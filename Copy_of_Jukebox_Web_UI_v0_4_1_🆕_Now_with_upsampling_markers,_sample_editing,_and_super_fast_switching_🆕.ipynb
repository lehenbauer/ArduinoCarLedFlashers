{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehenbauer/ArduinoCarLedFlashers/blob/master/Copy_of_Jukebox_Web_UI_v0_4_1_%F0%9F%86%95_Now_with_upsampling_markers%2C_sample_editing%2C_and_super_fast_switching_%F0%9F%86%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_SHA = 'v0.4.1'\n",
        "# TODO: Don't forget to change to release branch/version before publishing\n",
        "\n",
        "#@title Jukebox Web UI\n",
        "\n",
        "#@markdown This Notebook allows you to create music with OpenAIâ€™s Jukebox model using a simple, web-based UI that uses your Colab Notebook as a backend.\n",
        "#@markdown I strongly suggest that you refer to the [getting started page](https://github.com/vzakharov/jukebox-webui/blob/main/docs/getting-started.md) before running it.\n",
        "#@markdown ***\n",
        "\n",
        "#@markdown ## Parameters\n",
        "#@markdown ### *Song duration in seconds*\n",
        "total_duration = 80 #@param {type:\"slider\", min:60, max:300, step:10}\n",
        "#@markdown This is the only generation parameter you need to set in advance (instead of setting it in the UI later), as changing the duration requires reloading the model. If you do want to do this, stop the cell and run it again with the new value.\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### *Google Drive or Colabâ€™s (non-persistent!) storage*\n",
        "use_google_drive = True #@param{type:'boolean'}\n",
        "#@markdown Uncheck if you want to store data locally (or in your Colab instance) instead of Google Drive. Note that in this case your data will be lost when the Colab instance is stopped.\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### *Path for projects*\n",
        "base_path = '/content/drive/My Drive/jukebox-webui' #@param{type:'string'}\n",
        "#@markdown This is where your projects will go. ```/content/drive/My Drive/``` refers to the very top of your Google Drive. The folder will be automatically created if it doesnâ€™t exist, so you donâ€™t need to create it manually.\n",
        "#@markdown\n",
        "\n",
        "#@markdown ### *Path for models*\n",
        "models_path = '/content/drive/My Drive/jukebox-webui/_data' #@param{type:'string'}\n",
        "#@markdown This is where your models will be stored. This app is capable of loading the model from an arbitrary path, so storing it on Google Drive will save you the hassle (and time) of having to download or copy it every time you start the instance. The models will be downloaded automatically if they donâ€™t exist, so you donâ€™t need to download them manually.\n",
        "\n",
        "#@markdown ### *Optimized Jukebox* (experimental)\n",
        "use_optimized_jukebox = False #@param{type:'boolean'}\n",
        "#@markdown The optimized version by craftmine1000 uses less memory and can run on the free Colab tier. It also has a few other improvements too. Itâ€™s not as well-tested as the original one, though, so only set it if you have a good reason to.\n",
        "\n",
        "share_gradio = True #param{type:'boolean'}\n",
        "# â˜ï¸ Here and below, change #param to #@param if you want to be able to edit the value from the notebook interface. All of these are for advanced uses (and users), so donâ€™t bother with them unless you know what youâ€™re doing.\n",
        "\n",
        "#@markdown ### *Dev mode*\n",
        "DEV_MODE = False #@param{type:'boolean'}\n",
        "#@markdown Some dev-only stuff. Feel free to try it out, but donâ€™t expect it to work.\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Thatâ€™s it, you can now run the cell. Note that the first time you run it, it will take a few minutes to download the model. Afterwards, re-running the cell will be much faster.\n",
        "\n",
        "debug_gradio = True #param{type:'boolean'}\n",
        "\n",
        "reload_all = False #param{type:'boolean'}\n",
        "\n",
        "import glob\n",
        "import json\n",
        "import math\n",
        "import subprocess\n",
        "\n",
        "def print_gpu_and_memory():\n",
        "  # Print only gpu and memory info from print_gpu_and_memory()\n",
        "  print(\"ðŸ’» GPU, total memory, memory used:\")\n",
        "  !nvidia-smi --query-gpu=gpu_name,memory.total,memory.used --format=csv,noheader\n",
        "\n",
        "\n",
        "# If running locally, comment out the whole try-except block below, otherwise the !-prefixed commands will give a compile-time error (i.e. it will fail even if the corresponding code is not executed). Note that the app was never tested locally (tbh, I didnâ€™t even succeed installing Jukebox on my machine), so itâ€™s not guaranteed to work.\n",
        "\n",
        "\n",
        "# Print the IP address of the current Colab instance\n",
        "import socket\n",
        "\n",
        "try:\n",
        "  old_colab_instance_ip = colab_instance_ip\n",
        "except NameError:\n",
        "  old_colab_instance_ip = None\n",
        "\n",
        "colab_instance_ip = socket.gethostbyname(socket.gethostname())\n",
        "print(f'ðŸŒ IP address: {colab_instance_ip}')\n",
        "\n",
        "if colab_instance_ip == old_colab_instance_ip:\n",
        "  print('(Same as during the previous run)')\n",
        "else:\n",
        "  print('(New IP)')\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "  print_gpu_and_memory()\n",
        "  empty_cache()\n",
        "  print('Cache cleared.')\n",
        "  print_gpu_and_memory()\n",
        "\n",
        "  assert not reload_all\n",
        "  repeated_run\n",
        "  # ^ If this doesn't give an error, it means we're in Colab and re-running the notebook (because repeated_run is defined in the first run)\n",
        "  print('Re-running the notebook')\n",
        "\n",
        "except:\n",
        "  \n",
        "  if use_google_drive:\n",
        "    from google.colab import drive, runtime\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  if use_optimized_jukebox:\n",
        "    !pip install git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
        "  else:\n",
        "    !pip install git+https://github.com/Broccaloo/jukebox.git\n",
        "    \n",
        "  !pip install gradio==3.11.0\n",
        "\n",
        "  repeated_run = True\n",
        " \n",
        "\n",
        "# import glob\n",
        "import base64\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import hashlib\n",
        "import random\n",
        "import shutil\n",
        "import gradio as gr\n",
        "import librosa\n",
        "import os\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import urllib.request\n",
        "# import uuid\n",
        "import yaml\n",
        "\n",
        "import jukebox\n",
        "import jukebox.utils.dist_adapter as dist\n",
        "\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS\n",
        "from jukebox.hparams import Hyperparams, setup_hparams, REMOTE_PREFIX\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.remote_utils import download\n",
        "from jukebox.utils.sample_utils import get_starts\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "from jukebox.sample import sample_partial_window, load_prompts, upsample, sample_single_window\n",
        "\n",
        "### Model\n",
        "\n",
        "raw_to_tokens = 128\n",
        "chunk_size = 16\n",
        "lower_batch_size = 16\n",
        "lower_level_chunk_size = 32\n",
        "\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [ 0.5, 0.5, 0.125 ]\n",
        "hps.sample_length = int(total_duration * hps.sr // raw_to_tokens) * raw_to_tokens\n",
        "\n",
        "reload_dist = False #param{type:'boolean'}\n",
        "\n",
        "try:\n",
        "  assert not reload_dist and not reload_all\n",
        "  rank, local_rank, device\n",
        "  print('Dist already setup')\n",
        "except:\n",
        "  rank, local_rank, device = setup_dist_from_mpi()\n",
        "  print(f'Dist setup: rank={rank}, local_rank={local_rank}, device={device}')\n",
        "\n",
        "browser_timezone = None\n",
        "\n",
        "try:\n",
        "  keep_upsampling_after_restart\n",
        "except NameError:\n",
        "  keep_upsampling_after_restart = False\n",
        "\n",
        "if not keep_upsampling_after_restart:\n",
        "\n",
        "  class Upsampling:\n",
        "\n",
        "    project = None\n",
        "    sample_id = None\n",
        "\n",
        "    running = False\n",
        "    zs = None\n",
        "    level = None\n",
        "    metas = None\n",
        "    labels = None\n",
        "    priors = None\n",
        "    params = None\n",
        "\n",
        "    windows = []\n",
        "    window_index = 0\n",
        "    window_start_time = None\n",
        "    # Set time per window by default to 6 minutes (will be updated later) in timedelta format\n",
        "    time_per_window = timedelta(minutes=6)\n",
        "    windows_remaining = None\n",
        "    time_remaining = None\n",
        "    eta = None\n",
        "\n",
        "    status_markdown = None\n",
        "    should_refresh_audio = False\n",
        "\n",
        "    stop = False\n",
        "    kill_runtime_once_done = False\n",
        "\n",
        "print('Monkey patching Jukebox methods...')\n",
        "\n",
        "# Monkey patch load_checkpoint, allowing to load models from arbitrary paths\n",
        "def download_to_cache(remote_path, local_path):\n",
        "  print(f'Caching {remote_path} to {local_path}')\n",
        "  if not os.path.exists(os.path.dirname(local_path)):\n",
        "    print(f'Creating directory {os.path.dirname(local_path)}')\n",
        "    os.makedirs(os.path.dirname(local_path))\n",
        "  if not os.path.exists(local_path):\n",
        "    print('Downloading...')\n",
        "    download(remote_path, local_path)\n",
        "    print('Done.')\n",
        "  else:\n",
        "    print('Already cached.')\n",
        "\n",
        "def monkey_patched_load_checkpoint(path):\n",
        "  global models_path\n",
        "  restore = path\n",
        "  if restore.startswith(REMOTE_PREFIX):\n",
        "      remote_path = restore\n",
        "      local_path = os.path.join(models_path, remote_path[len(REMOTE_PREFIX):])\n",
        "      if dist.get_rank() % 8 == 0:\n",
        "          download_to_cache(remote_path, local_path)\n",
        "      restore = local_path\n",
        "  dist.barrier()\n",
        "  checkpoint = t.load(restore, map_location=t.device('cpu'))\n",
        "  print(\"Restored from {}\".format(restore))\n",
        "  return checkpoint\n",
        "\n",
        "jukebox.make_models.load_checkpoint = monkey_patched_load_checkpoint\n",
        "print('load_checkpoint monkey patched.')\n",
        "\n",
        "# # Download jukebox/models/5b/vqvae.pth.tar and jukebox/models/5b_lyrics/prior_level_2.pth.tar right away to avoid downloading them on the first run\n",
        "# for model_path in ['jukebox/models/5b/vqvae.pth.tar', 'jukebox/models/5b_lyrics/prior_level_2.pth.tar']:\n",
        "#   download_to_cache(f'{REMOTE_PREFIX}{model_path}', os.path.join(data_path, model_path))\n",
        "\n",
        "# Monkey patch load_audio, allowing for duration = None\n",
        "def monkey_patched_load_audio(file, sr, offset, duration, mono=False):\n",
        "  # Librosa loads more filetypes than soundfile\n",
        "  x, _ = librosa.load(file, sr=sr, mono=mono, offset=offset/sr, duration=None if duration is None else duration/sr)\n",
        "  if len(x.shape) == 1:\n",
        "      x = x.reshape((1, -1))\n",
        "  return x\n",
        "\n",
        "jukebox.utils.audio_utils.load_audio = monkey_patched_load_audio\n",
        "print('load_audio monkey patched.')\n",
        "\n",
        "sample_id_to_restart_upsampling_with = None\n",
        "\n",
        "def monkey_patched_sample_level(zs, labels, sampling_kwargs, level, prior, total_length, hop_length, hps):\n",
        "\n",
        "  global base_path\n",
        "\n",
        "  # The original code provides for shorter samples by sampling only a partial window, but we'll just throw an error for simplicity\n",
        "  assert total_length >= prior.n_ctx, f'Total length {total_length} is shorter than prior.n_ctx {prior.n_ctx}'\n",
        "\n",
        "  Upsampling.zs = zs\n",
        "  Upsampling.level = level\n",
        "\n",
        "  print(f\"Sampling level {level}\")\n",
        "  # Remember current time\n",
        "  start_time = datetime.now()\n",
        "  Upsampling.windows = get_starts(total_length, prior.n_ctx, hop_length)\n",
        "\n",
        "  print(f'Totally {len(Upsampling.windows)} windows at level {level}')\n",
        "\n",
        "  # Remove all windows whose start + n_ctx is less than however many samples we've already upsampled (at this level)\n",
        "  already_upsampled = Upsampling.zs[level].shape[1]\n",
        "  if already_upsampled > 0:\n",
        "    print(f'Already upsampled {already_upsampled} samples at level {level}')\n",
        "    Upsampling.windows = [ start for start in Upsampling.windows if start + prior.n_ctx > already_upsampled ]\n",
        "\n",
        "  if len(Upsampling.windows) == 0:\n",
        "    print(f'No windows to upsample at level {level}')\n",
        "  else:\n",
        "    print(f'Upsampling {len(Upsampling.windows)} windows, from {Upsampling.windows[0]} to {Upsampling.windows[-1]+prior.n_ctx}')\n",
        "\n",
        "    Upsampling.window_index = 0\n",
        "    for start in Upsampling.windows:\n",
        "\n",
        "      if Upsampling.stop:\n",
        "        print(f'Upsampling stopped for level {level}')\n",
        "        if Upsampling.level == 0:\n",
        "          Upsampling.stop = False\n",
        "        Upsampling.running = False\n",
        "\n",
        "        if sample_id_to_restart_upsampling_with is not None:\n",
        "          print(f'Upsampling will be restarted for sample {sample_id_to_restart_upsampling_with}')\n",
        "          restart_upsampling(sample_id_to_restart_upsampling_with)\n",
        "\n",
        "        break\n",
        "\n",
        "      Upsampling.window_start_time = datetime.now()\n",
        "      Upsampling.windows_remaining = len(Upsampling.windows) - Upsampling.window_index\n",
        "      Upsampling.time_remaining = Upsampling.time_per_window * Upsampling.windows_remaining\n",
        "      Upsampling.eta = datetime.now() + Upsampling.time_remaining\n",
        "      \n",
        "      Upsampling.status_markdown = f'Upsampling **window { Upsampling.window_index+1 } of { len(Upsampling.windows) }** for the **{ UI.UPSAMPLING_LEVEL_NAMES[2-level] }** level.\\n\\nEstimated level completion: **{ as_local_hh_mm(Upsampling.eta) }** your time.'\n",
        "          \n",
        "      # Print the status with an hourglass emoji in front of it\n",
        "      print(f'\\n\\nâ³ {Upsampling.status_markdown}\\n\\n')\n",
        "      \n",
        "      Upsampling.zs = sample_single_window(Upsampling.zs, labels, sampling_kwargs, level, prior, start, hps)\n",
        "\n",
        "      # Only update time_per_window we've sampled at least 2 windows (as the first window can take either a long or short time due to its size)\n",
        "      if Upsampling.window_index > 1:\n",
        "        Upsampling.time_per_window = datetime.now() - Upsampling.window_start_time\n",
        "\n",
        "      path = f'{base_path}/{Upsampling.project}/{Upsampling.sample_id}.z'\n",
        "      print(f'Saving upsampled z to {path}')\n",
        "      t.save(Upsampling.zs, path)\n",
        "      print('Done.')\n",
        "      Upsampling.should_refresh_audio = True\n",
        "      Upsampling.window_index += 1\n",
        "\n",
        "  if level == 0:\n",
        "    Upsampling.running = False\n",
        "    if Upsampling.kill_runtime_once_done:\n",
        "      print('Killing runtime')\n",
        "      runtime.unassign()\n",
        "\n",
        "  return Upsampling.zs\n",
        "\n",
        "jukebox.sample.sample_level = monkey_patched_sample_level\n",
        "print('sample_level monkey patched.')\n",
        "\n",
        "reload_prior = False #param{type:'boolean'}\n",
        "\n",
        "def load_top_prior():\n",
        "  global top_prior, vqvae, device\n",
        "\n",
        "  print('Loading top prior')\n",
        "  top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "\n",
        "if Upsampling.running:\n",
        "  print('''\n",
        "    !!! APP SET FOR UPSAMPLING !!!\n",
        "\n",
        "    To use the app for composing, stop execution, create a new cell and run the following code:\n",
        "\n",
        "    Upsampling.started = False\n",
        "\n",
        "    Then run the main cell again.\n",
        "  ''')\n",
        "else:\n",
        "\n",
        "  if not keep_upsampling_after_restart:\n",
        "\n",
        "    try:\n",
        "      vqvae, priors, top_prior\n",
        "\n",
        "      assert total_duration == calculated_duration and not reload_prior and not reload_all\n",
        "      print('Model already loaded.')\n",
        "    except:\n",
        "\n",
        "      print(f'Loading vqvae and top_prior for duration {total_duration}...')\n",
        "\n",
        "      vqvae, *priors = MODELS['5b_lyrics']\n",
        "\n",
        "      vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = hps.sample_length)), device)\n",
        "\n",
        "      load_top_prior()\n",
        "\n",
        "      calculated_duration = total_duration\n",
        "\n",
        "      empty_cache\n",
        "\n",
        "\n",
        "# If the base folder doesn't exist, create it\n",
        "if not os.path.isdir(base_path):\n",
        "  os.makedirs(base_path)\n",
        "\n",
        "try:\n",
        "  calculated_metas\n",
        "  print('Calculated metas already loaded.')\n",
        "except:\n",
        "  calculated_metas = {}\n",
        "  print('Calculated metas created.')\n",
        "\n",
        "loaded_settings = {}\n",
        "custom_parents = None\n",
        "\n",
        "class UI:\n",
        "\n",
        "  ### Meta\n",
        "\n",
        "  browser_timezone = gr.State()\n",
        "\n",
        "  separate_tab_warning = gr.Box(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  separate_tab_link = gr.Textbox(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  main_window = gr.Row(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  ### General\n",
        "\n",
        "  project_name = gr.Dropdown(\n",
        "    label = 'Project'\n",
        "  )\n",
        "\n",
        "  create_project_box = gr.Box(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  new_project_name = gr.Textbox(\n",
        "    label = 'Project name',\n",
        "    placeholder = 'lowercase-digits-and-dashes-only'\n",
        "  )\n",
        "\n",
        "  settings_box = gr.Accordion(\n",
        "    label = \"Settings\",\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  general_settings = [ project_name ]\n",
        "\n",
        "  ### Project-specific\n",
        "\n",
        "  ## Metas (artist, genre, lyrics)\n",
        "  artist = gr.Dropdown(\n",
        "    label = 'Artist'\n",
        "  )\n",
        "\n",
        "  genre = gr.Dropdown(\n",
        "    label = 'Genre'\n",
        "  )\n",
        "\n",
        "  lyrics = gr.Textbox(\n",
        "    label = 'Lyrics (optional)',\n",
        "    max_lines = 5,\n",
        "    placeholder = 'Shift+Enter for a new line'\n",
        "  )\n",
        "\n",
        "  metas = [ artist, genre, lyrics ]\n",
        "\n",
        "  n_samples = gr.Slider(\n",
        "    label = 'Number of samples',\n",
        "    minimum = 1,\n",
        "    maximum = 4,\n",
        "    step = 1\n",
        "  )\n",
        "\n",
        "  max_n_samples = gr.Number(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  temperature = gr.Slider(\n",
        "    label = 'Temperature',\n",
        "    minimum = 0.9,\n",
        "    maximum = 1.1,\n",
        "    step = 0.005\n",
        "  )\n",
        "\n",
        "  generation_length = gr.Slider(\n",
        "    label = 'Generation length, sec',\n",
        "    minimum = 0.5,\n",
        "    maximum = 10,\n",
        "    step = 0.1\n",
        "  )\n",
        "\n",
        "  generation_params = [ artist, genre, lyrics, n_samples, temperature, generation_length ]\n",
        "\n",
        "  getting_started_column = gr.Column( scale = 2, elem_id = 'getting-started-column' )\n",
        "  \n",
        "  workspace_column = gr.Column( scale = 3, visible = False )\n",
        "\n",
        "  primed_audio = gr.Audio(\n",
        "    label = 'Audio to start from (optional)',\n",
        "    source = 'microphone'\n",
        "  )\n",
        "\n",
        "  # Virtual timestamp textbox to do certain things once the audio is primed (and this textbox is updated), accurate to the millisecond\n",
        "  prime_timestamp = gr.Textbox(\n",
        "    value = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  first_generation_row = gr.Row(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  generation_progress = gr.Markdown('Generation status will be shown here', elem_id = 'generation-progress')\n",
        "\n",
        "  routed_sample_id = gr.State()\n",
        "\n",
        "  sample_tree_row = gr.Row(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  sample_tree = gr.Dropdown(\n",
        "    label = 'Sample tree',\n",
        "  )\n",
        "\n",
        "  show_leafs_only = gr.Checkbox(\n",
        "    label = 'Hide branch samples',\n",
        "  )\n",
        "\n",
        "  branch_sample_count = gr.Number(\n",
        "    label = '# branch samples',\n",
        "  )\n",
        "  leaf_sample_count = gr.Number(\n",
        "    label = '# leaf samples',\n",
        "  )\n",
        "\n",
        "\n",
        "  picked_sample = gr.Radio(\n",
        "    label = 'Variations',\n",
        "  )\n",
        "\n",
        "  picked_sample_updated = gr.Number( 0, visible = False )\n",
        "\n",
        "  sample_box = gr.Box(\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  upsampling_accordion = gr.Accordion(\n",
        "    label = 'Upsampling',\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  UPSAMPLING_LEVEL_NAMES = [ 'Raw', 'Midsampled', 'Upsampled' ]\n",
        "\n",
        "  upsampling_level = gr.Dropdown(\n",
        "    label = 'Upsampling level',\n",
        "    choices = [ 'Raw' ],\n",
        "    value = 'Raw',\n",
        "  )\n",
        "\n",
        "  upsample_rendering = gr.Dropdown(\n",
        "    label = 'Render...',\n",
        "    type = 'index',\n",
        "    choices = [ 'Channel 1', 'Channel 2', 'Channel 3', 'Pseudo-stereo', 'Pseudo-stereo with delay' ],\n",
        "    value = 'Pseudo-stereo with delay',\n",
        "  )\n",
        "\n",
        "  combine_upsampling_levels = gr.Checkbox(\n",
        "    label = 'Combine levels',\n",
        "    value = True\n",
        "  )\n",
        "\n",
        "  continue_upsampling_button = gr.Button('Continue upsampling', visible = False )\n",
        "\n",
        "  upsampled_lengths = gr.Textbox(visible = False)\n",
        "  # (Comma-separated list of audio lengths by upsampling level, e.g. '0.5,1'. If only midsampled audio is available, the list will only contain one element, e.g. '1'.)\n",
        "\n",
        "  current_chunks = gr.File(\n",
        "    elem_id = 'current-chunks',\n",
        "    type = 'binary',\n",
        "    visible = False,\n",
        "    file_count = 'multiple'\n",
        "  )\n",
        "\n",
        "  sibling_chunks = gr.File(\n",
        "    elem_id = 'sibling-chunks',\n",
        "    type = 'binary',\n",
        "    visible = False,\n",
        "    file_count = 'multiple'\n",
        "  )\n",
        "  \n",
        "  audio_waveform = gr.HTML(\n",
        "    elem_id = 'audio-waveform'\n",
        "  )\n",
        "\n",
        "  audio_timeline = gr.HTML(\n",
        "    elem_id = 'audio-timeline'\n",
        "  )\n",
        "\n",
        "  compose_row = gr.Box(\n",
        "    elem_id = 'compose-row',\n",
        "  )\n",
        "\n",
        "  go_to_parent_button = gr.Button(\n",
        "    value = '<',\n",
        "  )\n",
        "\n",
        "  go_to_children_button = gr.Button(\n",
        "    value = '>',\n",
        "  )\n",
        "\n",
        "  total_audio_length = gr.Number(\n",
        "    label = 'Total audio length, sec',\n",
        "    elem_id = 'total-audio-length',\n",
        "    interactive = False,\n",
        "    visible = False\n",
        "  )\n",
        "\n",
        "  preview_just_the_last_n_sec = gr.Number(\n",
        "    label = 'Preview the last ... seconds',\n",
        "    elem_id = 'preview-last-n-sec'\n",
        "  )\n",
        "\n",
        "  cut_audio_specs = gr.Textbox(\n",
        "    label = 'Cut, trim, merge',\n",
        "    placeholder = 'See accordion below for syntax',\n",
        "    elem_id = 'cut-audio-specs',\n",
        "  )\n",
        "\n",
        "  cut_audio_preview_button = gr.Button( 'Preview', visible = False, variant = 'secondary' )\n",
        "  cut_audio_apply_button = gr.Button( 'Apply', visible = False, variant = 'primary' )\n",
        "\n",
        "  sample_to_upsample = gr.Textbox(\n",
        "    label = 'Sample to upsample',\n",
        "    placeholder = 'Choose a sample in the Workspace tab first',\n",
        "    interactive = False,\n",
        "  )\n",
        "\n",
        "  genre_for_upsampling_left_channel = gr.Dropdown(\n",
        "    label = 'Genre for upsampling (left channel)'\n",
        "  )\n",
        "\n",
        "  genre_for_upsampling_center_channel = gr.Dropdown(\n",
        "    label = 'Genre for upsampling (center channel)'\n",
        "  )\n",
        "\n",
        "  genre_for_upsampling_right_channel = gr.Dropdown(\n",
        "    label = 'Genre for upsampling (right channel)'\n",
        "  )\n",
        "\n",
        "  kill_runtime_once_done = gr.Checkbox(\n",
        "    label = 'Kill runtime once done',\n",
        "    value = False\n",
        "  )\n",
        "\n",
        "  upsample_button = gr.Button('Start upsampling', variant=\"primary\", elem_id='upsample-button')\n",
        "\n",
        "  upsampling_status = gr.Markdown('Upsampling progress will be shown here', visible = False)\n",
        "\n",
        "  upsampling_audio_refresher = gr.Number( value = 0, visible = False )\n",
        "  # Note: for some reason, Gradio doesn't monitor programmatic changes to a checkbox, so we use a number instead\n",
        "\n",
        "  upsampling_refresher = gr.Number( value = 0, visible = False )\n",
        "\n",
        "  upsampling_running = gr.Number( visible = False )\n",
        "\n",
        "  upsampling_triggered_by_button = gr.Checkbox( visible = False, value = False )\n",
        "\n",
        "  project_settings = [ \n",
        "    *generation_params, sample_tree, show_leafs_only, preview_just_the_last_n_sec,\n",
        "    genre_for_upsampling_left_channel, genre_for_upsampling_center_channel, genre_for_upsampling_right_channel \n",
        "  ]\n",
        "\n",
        "  input_names = { input: name for name, input in locals().items() if isinstance(input, gr.components.FormComponent) }\n",
        "\n",
        "  inputs_by_name = { name: input for name, input in locals().items() if isinstance(input, gr.components.FormComponent) }\n",
        "\n",
        "def as_local_hh_mm(dt, include_seconds = False):\n",
        "  return dt.astimezone(browser_timezone).strftime('%H:%M:%S' if include_seconds else '%H:%M')\n",
        "\n",
        "def convert_name(name):\n",
        "  return re.sub(r'[^a-z0-9]+', '-', name.lower())\n",
        "\n",
        "def create_project(name):\n",
        "\n",
        "  global base_path\n",
        "\n",
        "  name = convert_name(name)\n",
        "\n",
        "  print(f'Creating project {name}...')\n",
        "\n",
        "  os.makedirs(f'{base_path}/{name}')\n",
        "\n",
        "  print(f'Project {name} created!')\n",
        "\n",
        "  return gr.update(\n",
        "    choices = get_projects(),\n",
        "    value = name\n",
        "  )\n",
        "\n",
        "def convert_audio_to_sample(project_name, audio, sec_to_trim_primed_audio, show_leafs_only):\n",
        "\n",
        "  global hps, base_path\n",
        "\n",
        "  # audio is of the following form:\n",
        "  # (48000, array([        0,         0,         0, ..., -26209718, -25768554,       -25400996], dtype=int32))\n",
        "  # dtype=int16 is also possible\n",
        "  # Or, if it is a stereo file, audio[1] is [[left, right], [left, right], ...]\n",
        "  \n",
        "  print(f'Audio: {audio}')\n",
        "  # breakpoint()\n",
        "  print(f'Audio length: {len(audio[1])} samples, sample rate: {audio[0]} Hz')\n",
        "\n",
        "  # If it is a stereo file, we need to convert it to mono by averaging the left and right channels\n",
        "  if len(audio[1].shape) > 1:\n",
        "    audio = (audio[0], audio[1].mean(axis=1))\n",
        "    print(f'Converted stereo to mono (shape: {audio[1].shape})')\n",
        "\n",
        "  if sec_to_trim_primed_audio:\n",
        "    audio = (audio[0], audio[1][:int(audio[0] * sec_to_trim_primed_audio)])\n",
        "    print(f'Trimmed audio to {sec_to_trim_primed_audio} seconds')\n",
        "\n",
        "  # Convert the audio to float depending on the dtype\n",
        "\n",
        "  x = audio[1] / 2**31 if audio[1].dtype == np.int32 else audio[1] / 2**15\n",
        "  print(f'Converted to [-1, 1]; min = {x.min()}, max = {x.max()}')\n",
        "\n",
        "  # Resample the audio to hps.sr (if needed)\n",
        "\n",
        "  if audio[0] != hps.sr:\n",
        "    x = librosa.resample(x, audio[0], hps.sr)\n",
        "    print(f'Resampled audio to {hps.sr}')\n",
        "\n",
        "  # Convert the audio to a tensor (e.g. from array([[-1.407e-03, -4.461e-04, ..., -3.042e-05,  1.277e-05]], dtype=float32) to tensor([[-1.407e-03], [-4.461e-04], ..., [-3.042e-05], [ 1.277e-05]], dtype=float32))\n",
        "\n",
        "  if len(x.shape) == 1:\n",
        "    x = x.reshape((1, -1))\n",
        "    print(f'Reshaped audio to {x.shape}')\n",
        "\n",
        "  x = x.T\n",
        "  print(f'Transposed audio to {x.shape}')\n",
        "  \n",
        "  xs = [ x ]\n",
        "\n",
        "  print(f'Created {len(xs)} samples of {x.shape} shape each')\n",
        "\n",
        "  x = t.stack([t.from_numpy(x) for x in xs])\n",
        "  print(f'Stacked samples to {x.shape}')\n",
        "\n",
        "  x = x.to(device, non_blocking=True)\n",
        "  print(f'Moved samples to {device}')\n",
        "\n",
        "  zs = top_prior.encode( x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0] )\n",
        "  print(f'Encoded audio to zs of shape {[ z.shape for z in zs ]}')\n",
        "\n",
        "  primed_sample_id = f'{project_name}-{get_first_free_index(project_name)}'\n",
        "  filename = f'{base_path}/{project_name}/{primed_sample_id}.z'\n",
        "  t.save(zs, filename)\n",
        "\n",
        "  return {\n",
        "    UI.sample_tree: gr.update(\n",
        "      choices = get_samples(project_name, show_leafs_only),\n",
        "      value = primed_sample_id\n",
        "    ),\n",
        "    UI.prime_timestamp: datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),\n",
        "    UI.first_generation_row: HIDE,\n",
        "  }\n",
        "\n",
        "def delete_sample(project_name, sample_id, confirm):\n",
        "\n",
        "  if not confirm:\n",
        "    return {}\n",
        "  \n",
        "  # New child sample is the one that goes after the deleted sample\n",
        "  siblings = get_siblings(project_name, sample_id)\n",
        "  current_index = siblings.index(sample_id)\n",
        "  new_sibling_to_use = siblings[ current_index + 1 ] if current_index < len(siblings) - 1 else siblings[ current_index - 1 ]\n",
        "\n",
        "  # Remove the to-be-deleted sample from the list of child samples\n",
        "  siblings.remove(sample_id)\n",
        "\n",
        "  # Delete the sample\n",
        "  filename = f'{base_path}/{project_name}/{sample_id}'\n",
        "\n",
        "  for extension in [ '.z', '.wav' ]:\n",
        "    if os.path.isfile(f'{filename}{extension}'):\n",
        "      os.remove(f'{filename}{extension}')\n",
        "      print(f'Deleted {filename}{extension}')\n",
        "    else:\n",
        "      print(f'No {filename}{extension} found')\n",
        "  return {\n",
        "    UI.picked_sample: gr.update(\n",
        "      choices = siblings,\n",
        "      value = new_sibling_to_use,\n",
        "    ),\n",
        "    UI.sample_box: gr.update(\n",
        "      visible = len(siblings) > 0\n",
        "    ),            \n",
        "  }\n",
        "\n",
        "def generate(project_name, parent_sample_id, show_leafs_only, artist, genre, lyrics, n_samples, temperature, generation_length):\n",
        "\n",
        "  print(f'Generating {n_samples} sample(s) of {generation_length} sec each for project {project_name}...')\n",
        "\n",
        "  global total_duration\n",
        "  global calculated_metas\n",
        "  global hps, raw_to_tokens, chunk_size, lower_batch_size, lower_level_chunk_size\n",
        "  global top_prior, device, priors\n",
        "  global metas, labels\n",
        "\n",
        "  hps.n_samples = n_samples\n",
        "\n",
        "  # If metas or n_samples have changed, recalculate the metas\n",
        "  if calculated_metas != dict( artist = artist, genre = genre, lyrics = lyrics ) or len(metas) != n_samples:\n",
        "\n",
        "    print(f'Metas or n_samples have changed, recalculating the model for {artist}, {genre}, {lyrics}, {n_samples} samples...')\n",
        "\n",
        "    metas = [dict(\n",
        "      artist = artist,\n",
        "      genre = genre,\n",
        "      total_length = hps.sample_length,\n",
        "      offset = 0,\n",
        "      lyrics = lyrics,\n",
        "    )] * n_samples\n",
        "\n",
        "    labels = top_prior.labeller.get_batch_labels(metas, device)\n",
        "\n",
        "    calculated_metas = {\n",
        "      'artist': artist,\n",
        "      'genre': genre,\n",
        "      'lyrics': lyrics\n",
        "    }\n",
        "\n",
        "    print('Done recalculating the model')\n",
        "\n",
        "  print(f'Generating {generation_length} seconds for {project_name}...')\n",
        "\n",
        "  if parent_sample_id:\n",
        "\n",
        "    zs = t.load(f'{base_path}/{project_name}/{parent_sample_id}.z')\n",
        "    print(f'Loaded parent sample {parent_sample_id} of shape {[ z.shape for z in zs ]}')\n",
        "    zs = [ z[0].repeat(n_samples, 1) for z in zs ]\n",
        "    print(f'Converted to shape {[ z.shape for z in zs ]}')\n",
        "\n",
        "  else:\n",
        "    zs = [ t.zeros(n_samples, 0, dtype=t.long, device='cuda') for _ in range(3) ]\n",
        "    print('No parent sample or primer provided, starting from scratch')\n",
        "  \n",
        "  tokens_to_sample = seconds_to_tokens(generation_length)\n",
        "  sampling_kwargs = dict(\n",
        "    temp=temperature, fp16=True, max_batch_size=lower_batch_size,\n",
        "    chunk_size=lower_level_chunk_size\n",
        "  )\n",
        "\n",
        "  print(f'zs: {[ z.shape for z in zs ]}')\n",
        "  zs = sample_partial_window(zs, labels, sampling_kwargs, 2, top_prior, tokens_to_sample, hps)\n",
        "  print(f'Generated zs of shape {[ z.shape for z in zs ]}')\n",
        "\n",
        "  wavs = vqvae.decode(zs[2:], start_level=2).cpu().numpy()\n",
        "  print(f'Generated wavs of shape {wavs.shape}')\n",
        "\n",
        "  prefix = get_prefix(project_name, parent_sample_id)\n",
        "  # For each sample, write the z (a subarray of zs)\n",
        "\n",
        "  try:\n",
        "    first_new_child_index = get_first_free_index(project_name, parent_sample_id)\n",
        "  except Exception as e:\n",
        "    print(f'Something went wrong: {e}')\n",
        "    first_new_child_index = random.randrange(1e6, 1e7)\n",
        "    print(f'Using random index {first_new_child_index} as a fallback')\n",
        "\n",
        "  for i in range(n_samples):\n",
        "    id = f'{prefix}{first_new_child_index + i}'\n",
        "    filename = f'{base_path}/{project_name}/{id}'\n",
        "\n",
        "    # zs is a list of 3 tensors, each of shape (n_samples, n_tokens)\n",
        "    # To write the z for a single sample, we need to take a subarray of each tensor\n",
        "    this_sample_zs = [ z[i:i+1] for z in zs ]\n",
        "\n",
        "    t.save(this_sample_zs, f'{filename}.z')\n",
        "    print(f'Wrote {filename}.z')\n",
        "\n",
        "  return {\n",
        "    UI.sample_tree: gr.update(\n",
        "      choices = get_samples(project_name, show_leafs_only),\n",
        "      value = id\n",
        "    ),\n",
        "    UI.generation_progress: f'Generation completed at {datetime.now().strftime(\"%H:%M:%S\")}'\n",
        "  }\n",
        "\n",
        "\n",
        "def get_zs(project_name, sample_id, seek_upsampled = False):\n",
        "  global base_path\n",
        "\n",
        "  filename = f'{base_path}/{project_name}/{sample_id}.z'\n",
        "  zs = t.load(filename)\n",
        "  if not is_upsampled(zs) and seek_upsampled:\n",
        "    upsampled_ancestor = get_first_upsampled_ancestor_zs(project_name, sample_id)\n",
        "    if upsampled_ancestor:\n",
        "      zs[:-1] = upsampled_ancestor[:-1]\n",
        "  print(f'Loaded {filename}')\n",
        "  return zs\n",
        "\n",
        "def save_zs(zs, project_name, sample_id):\n",
        "  global base_path\n",
        "\n",
        "  filename = f'{base_path}/{project_name}/{sample_id}.z'\n",
        "  t.save(zs, filename)\n",
        "  print(f'Wrote {filename}')\n",
        "\n",
        "def backup_zs(zs, project_name, sample_id):\n",
        "  global base_path\n",
        "\n",
        "  timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "  filename = f'{base_path}/{project_name}/bak/{sample_id}_{timestamp}.z'\n",
        "  if not os.path.exists(os.path.dirname(filename)):\n",
        "    os.makedirs(os.path.dirname(filename))\n",
        "  t.save(zs, filename)\n",
        "  print(f'Backed up {filename}')\n",
        "\n",
        "def get_levels(zs):\n",
        "\n",
        "  levels = []\n",
        "  for i in range(3):\n",
        "    if zs[i].shape[1] == 0:\n",
        "      # print(f'Level {i} is empty, skipping')\n",
        "      pass\n",
        "    else:\n",
        "      # We also need to make sure that, if it's not level 2, there are exactly 3 samples in the tensor\n",
        "      # Otherwise it's a primed sample, not the one we created during upsampling\n",
        "      # I agree this is a bit hacky; in the future we need to make sure that the primed samples are not saved for levels other than 2\n",
        "      # But for backwards compatibility, we need to keep this check\n",
        "      if i != 2 and zs[i].shape[0] != 3:\n",
        "        # print(f\"Level {i}'s tensor has {z[i].shape[0]} samples, not 3, skipping\")\n",
        "        pass\n",
        "      else:\n",
        "        levels.append(i)\n",
        "\n",
        "  return levels\n",
        "\n",
        "def is_upsampled(zs):\n",
        "  # Yes if there are at least 2 levels\n",
        "  return len(get_levels(zs)) >= 2\n",
        "\n",
        "def get_first_upsampled_ancestor_zs(project_name, sample_id):\n",
        "  zs = get_zs(project_name, sample_id)\n",
        "  # print(f'Looking for the first upsampled ancestor of {sample_id}')\n",
        "  if is_upsampled(zs):\n",
        "    print(f'Found upsampled ancestor: {sample_id}')\n",
        "    return zs\n",
        "  else:\n",
        "    parent = get_parent(project_name, sample_id)\n",
        "    if parent:\n",
        "      return get_first_upsampled_ancestor_zs(project_name, parent)\n",
        "    else:\n",
        "      print(f'No upsampled ancestor found for {sample_id}')\n",
        "      return None\n",
        "\n",
        "def get_audio(project_name, sample_id, cut_audio, preview_sec, level=None, stereo_rendering=3, combine_levels=True):\n",
        "\n",
        "  print(f'Generating audio for {project_name}/{sample_id} (level {level}, stereo rendering {stereo_rendering}, combine levels {combine_levels})')\n",
        "  print(f'Cut: {cut_audio}, preview: {preview_sec}')\n",
        "\n",
        "  # Get current GPU memory usage. If it's above 12GB, empty the cache\n",
        "  memory = t.cuda.memory_allocated()\n",
        "  print(f'GPU memory usage is {memory / 1e9:.1f} GB')\n",
        "  if t.cuda.memory_allocated() > 12e9:\n",
        "    print('GPU memory usage is above 12GB, clearing the cache')\n",
        "    empty_cache()\n",
        "    print(f'GPU memory usage is now {t.cuda.memory_allocated() / 1e9:1f} GB')\n",
        "\n",
        "  global base_path, hps\n",
        "\n",
        "  zs = get_zs(project_name, sample_id, seek_upsampled=True)\n",
        "\n",
        "  # If no level is specified, use 2 (and then go downwards if combine_levels is True)\n",
        "  if level is None:\n",
        "    level = 2\n",
        "\n",
        "  z = zs[level]\n",
        "  # z is of shape torch.Size([1, n_tokens])\n",
        "  # print(f'Loaded {filename}.z at level {level}, shape: {z.shape}')\n",
        "\n",
        "  if cut_audio:\n",
        "    z = cut_z(z, cut_audio, level)\n",
        "  \n",
        "  # Update audio_length\n",
        "  audio_length = int( tokens_to_seconds(z.shape[1], level) * 100 ) / 100\n",
        "  \n",
        "  if preview_sec:\n",
        "    seconds_to_cut_from_start = audio_length - abs(preview_sec) if preview_sec < 0 else preview_sec\n",
        "    # For negative values, we need to replace \"-\" with \"<\" because \"-\" is used to indicate a range\n",
        "    z = cut_z(z, f'-{seconds_to_cut_from_start}', level)\n",
        "  else:\n",
        "    seconds_to_cut_from_start = 0\n",
        "\n",
        "  def decode(z):\n",
        "    if z.shape[1] > 0:\n",
        "      wav = vqvae.decode([ z ], start_level=level, end_level=level+1).cpu().numpy()\n",
        "      # the decoded wav is of shape (n_samples, sample_length, 1). We will convert it later to (n_samples, 1 or 2 depending on stereo_rendering)\n",
        "    else:\n",
        "      # If the sample is empty, we need to create an empty wav of the right shape\n",
        "      wav = np.zeros((z.shape[0], 0, 1))\n",
        "    return wav\n",
        "  \n",
        "  # If z is longer than 30 seconds, there will likely be not enough RAM to decode it in one go\n",
        "  # In this case, we'll split it into 30-second chunks (with a 5-second overlap), decode each chunk separately, and concatenate the results, crossfading the overlaps\n",
        "  if z.shape[1] < seconds_to_tokens(30, level):\n",
        "    wav = decode(z)\n",
        "  else:\n",
        "    chunk_size = seconds_to_tokens(30, level)\n",
        "    overlap_size = seconds_to_tokens(5, level)\n",
        "    print(f'z is too long ({z.shape[1]} tokens), splitting into chunks of {chunk_size} tokens, with a {overlap_size} token overlap')\n",
        "    wav = None\n",
        "    # Keep in mind that the last chunk can be shorter if the total length is not a multiple of chunk_size)\n",
        "    for i in range(0, z.shape[1], chunk_size - overlap_size):\n",
        "\n",
        "      # If this is the last chunk, make the chunk_size smaller if necessary\n",
        "      overflow = i + chunk_size - z.shape[1]\n",
        "      is_last_chunk = overflow > 0\n",
        "      if is_last_chunk:\n",
        "        chunk_size -= overflow\n",
        "        # print(f'Last chunk, reduced chunk_size from {chunk_size + overflow} to {chunk_size} tokens')\n",
        "\n",
        "      left_overlap_z = z[ :, i:i+overlap_size ]\n",
        "      # print(f'Left overlap (tokens): {left_overlap_z.shape[1]}')\n",
        "      left_overlap = decode(left_overlap_z)\n",
        "      # print(f'Left overlap (quants): {left_overlap.shape[1]}')\n",
        "\n",
        "\n",
        "      def fade(overlap, direction):\n",
        "        # To fade in, we need to add 1/4 of the overlap as silence, 2/4 of the overlap as a linear ramp, and 1/4 of the overlap as full volume\n",
        "        is_fade_in = direction == 'in'\n",
        "        overlap_quants = overlap.shape[1]\n",
        "        silence_quants = int( overlap_quants / 4 )\n",
        "        ramp_quants = int( overlap_quants / 2 )\n",
        "        if is_fade_in:\n",
        "          overlap[:, :silence_quants, :] = 0\n",
        "        else:\n",
        "          overlap[:, -silence_quants:, :] = 0\n",
        "        start = 0 if is_fade_in else 1\n",
        "        overlap[:, silence_quants:-silence_quants, :] *= np.linspace(start, 1 - start, ramp_quants).reshape(1, -1, 1)\n",
        "        return overlap\n",
        "\n",
        "      if wav is not None:\n",
        "\n",
        "        # Fade in the left overlap and add it to the existing wav if it's not empty (i.e. if this is not the first chunk)\n",
        "        left_overlap = fade(left_overlap, 'in')\n",
        "        # print(f'Faded in left overlap')\n",
        "        # # Show as plot\n",
        "        # plt.plot(left_overlap[0, :, 0])\n",
        "        # plt.show()\n",
        "\n",
        "        wav[ :, -left_overlap.shape[1]: ] += left_overlap\n",
        "        # print(f'Added left overlap to existing wav:')\n",
        "        # # Plot the resulting (faded-in + previous fade-out) overlap\n",
        "        # plt.plot(wav[0, -left_overlap.shape[1]:, 0])\n",
        "        # plt.show()\n",
        "\n",
        "        print(f'Added left overlap to wav, overall shape now: {wav.shape}')\n",
        "\n",
        "      else:\n",
        "        wav = left_overlap\n",
        "        print(f'Created wav with left overlap')\n",
        "\n",
        "      # We'll also won't need right overlap for the last chunk\n",
        "      main_chunk_z = z[ :, i+overlap_size: i+chunk_size-overlap_size if not is_last_chunk else i+chunk_size ]\n",
        "      print(f'Main chunk (tokens): {main_chunk_z.shape[1]}')\n",
        "\n",
        "      if main_chunk_z.shape[1] > 0:\n",
        "\n",
        "        main_chunk = decode(main_chunk_z)\n",
        "        print(f'Main chunk (quants): {main_chunk.shape[1]}')\n",
        "\n",
        "        # Add the main chunk to the existing wav\n",
        "        wav = np.concatenate([ wav, main_chunk ], axis=1)\n",
        "        print(f'Added main chunk to wav, overall shape now: {wav.shape}')\n",
        "\n",
        "      else:\n",
        "        print('Main chunk is empty, skipping')\n",
        "        continue\n",
        "\n",
        "      # Fade out the right overlap, unless this is the last chunk\n",
        "      if not is_last_chunk:\n",
        "\n",
        "        right_overlap_z = z[ :, i+chunk_size-overlap_size:i+chunk_size ]\n",
        "        # print(f'Right overlap (tokens): {right_overlap_z.shape[1]}')\n",
        "\n",
        "        right_overlap = decode(right_overlap_z)\n",
        "        # print(f'Right overlap (quants): {right_overlap.shape[1]}')\n",
        "\n",
        "        right_overlap = fade(right_overlap, 'out')\n",
        "        # print(f'Faded out right overlap')\n",
        "        # # Show as plot\n",
        "        # plt.plot(right_overlap[0, :, 0])\n",
        "        # plt.show()\n",
        "\n",
        "        # Add the right overlap to the existing wav\n",
        "        wav = np.concatenate([ wav, right_overlap ], axis=1)\n",
        "        # print(f'Added right overlap to wav, overall shape now: {wav.shape}')\n",
        "      \n",
        "      else:\n",
        "\n",
        "        print(f'Last chunk, not adding right overlap')\n",
        "        break\n",
        "      \n",
        "      print(f'Decoded {i+chunk_size} tokens out of {z.shape[1]}, wav shape: {wav.shape}')\n",
        "\n",
        "  # wav is now of shape (n_samples, sample_length, 1)\n",
        "  # If this is level 2, we want just (sample_length,), picking the first sample if there are multiple\n",
        "  if level == 2:\n",
        "    wav = wav[0, :, 0]\n",
        "\n",
        "  # Otherwise, this is a batch of upsampled audio, so we need to act depending on the upsample_rendering parameter\n",
        "  else:\n",
        "\n",
        "    # upsample_rendering of 0, 1 or 2 means we just need to pick one of the samples\n",
        "    if stereo_rendering < 3:\n",
        "\n",
        "      wav = wav[stereo_rendering, :, 0]\n",
        "    \n",
        "    # upsample_rendering of 3 means we need to convert the audio to stereo, putting sample 0 to the left, 1 to the center, and 2 to the right\n",
        "    # 4 means we also want to add a delay of 20 ms for the left and 40 ms for the right channel\n",
        "\n",
        "    else:\n",
        "\n",
        "      def to_stereo(wav, stereo_delay_ms=0):\n",
        "\n",
        "        # A stereo wav is of form (sample_length + double the delay, 2)\n",
        "        delay_quants = int( stereo_delay_ms * hps.sr / 1000 )\n",
        "        stereo = np.zeros((wav.shape[1] + 2 * delay_quants, 2))\n",
        "        # First let's convert the wav to [n_quants, n_samples] by getting rid of the last dimension and transposing the rest\n",
        "        wav = wav[:, :, 0].T\n",
        "        # print(f'Converted wav to shape {wav.shape}')\n",
        "        # Take sample 0 for left channel (delayed once), 1 for both channels (non-delayed), and sample 2 for right channel (delayed twice)\n",
        "        if delay_quants:\n",
        "          stereo[ delay_quants: -delay_quants, 0 ] = wav[ :, 0 ]\n",
        "          stereo[ 2 * delay_quants:, 1 ] = wav[ :, 2 ]\n",
        "          stereo[ : -2 * delay_quants, 0 ] += wav[ :, 1 ]\n",
        "          stereo[ : -2 * delay_quants, 1 ] += wav[ :, 1 ]\n",
        "        else:\n",
        "          stereo[ :, 0 ] = wav[ :, 0 ] + wav[ :, 1 ]\n",
        "          stereo[ :, 1 ] = wav[ :, 2 ] + wav[ :, 1 ]\n",
        "        # Now we have max amplitude of 2, so we need to divide by 2\n",
        "        stereo /= 2\n",
        "\n",
        "        # print(f'Converted to stereo with delay {stereo_delay_ms} ms, current shape: {stereo.shape}, max/min amplitudes: {np.max(stereo)}/{np.min(stereo)}')\n",
        "\n",
        "        return stereo\n",
        "      \n",
        "      wav = to_stereo(wav, stereo_delay_ms=20 if stereo_rendering == 4 else 0)\n",
        "\n",
        "  upsampled_lengths = [ 0, 0 ]\n",
        "  if combine_levels:\n",
        "\n",
        "    available_levels = get_levels(zs)\n",
        "    combined_wav = None\n",
        "\n",
        "    for sub_level in available_levels:\n",
        "\n",
        "      if sub_level < level:\n",
        "        sub_wav = get_audio(project_name, sample_id, cut_audio, seconds_to_cut_from_start, sub_level, stereo_rendering, combine_levels=False)[0]\n",
        "        upsampled_lengths[sub_level] = sub_wav.shape[0] / hps.sr + seconds_to_cut_from_start\n",
        "      else:\n",
        "        sub_wav = wav\n",
        "        # If the wav is mono, we need to convert it to stereo by using the same values for both channels\n",
        "        # (Note that this is most always the case, since the original audio is always mono, and this function is likely to be called for the original level, but we're abstracting it just in case)\n",
        "        if sub_wav.ndim == 1:\n",
        "          sub_wav = np.stack([ sub_wav, sub_wav ], axis=1)\n",
        "\n",
        "      if combined_wav is None:\n",
        "        combined_wav = sub_wav\n",
        "        print(f'Created wav of length {combined_wav.shape[0]} for level {sub_level}')\n",
        "      else:\n",
        "        n_to_add = sub_wav.shape[0] - combined_wav.shape[0]\n",
        "        # (This might be confusing why we are subtracting the shape of combined wav from the \"sub\" wav, but it's because the higher level \"sub\" wav is the one that is being upsampled, so it's the one that needs to be longer. The entire terminology with levels going backwards while the quality goes up is confusing, but we work with what we have)\n",
        "        if n_to_add > 0:\n",
        "          print(f'Adding {n_to_add} samples for level {sub_level}')\n",
        "          combined_wav = np.concatenate([ combined_wav, sub_wav[ -n_to_add: ] ], axis=0)\n",
        "\n",
        "    wav = combined_wav\n",
        "\n",
        "  print(f'Generated audio of length {len(wav)} ({ len(wav) / hps.sr } seconds); original length: {audio_length} seconds.')\n",
        "\n",
        "  return wav, audio_length, upsampled_lengths\n",
        "\n",
        "# def get_audio_being_upsampled():\n",
        "\n",
        "#   if not Upsampling.running:\n",
        "#     return None\n",
        "\n",
        "#   zs = Upsampling.zs\n",
        "#   level = Upsampling.level\n",
        "\n",
        "#   print(f'Generating audio for level {level}')\n",
        "  \n",
        "#   x = Upsampling.priors[level].decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
        "\n",
        "#   # x is of shape (1, sample_length, 1), we want (sample_length,)\n",
        "#   wav = x[0, :, 0].cpu().numpy()\n",
        "#   return gr.update(\n",
        "#     visible = True,\n",
        "#     value = ( hps.sr, wav ),\n",
        "#   )\n",
        "\n",
        "def get_children(project_name, parent_sample_id, include_custom=True):\n",
        "\n",
        "  global base_path\n",
        "\n",
        "  prefix = get_prefix(project_name, parent_sample_id)\n",
        "  child_ids = []\n",
        "  for filename in os.listdir(f'{base_path}/{project_name}'):\n",
        "    match = re.match(f'{prefix}(\\d+)\\\\.zs?$', filename)\n",
        "    if match:\n",
        "      child_ids += [ filename.split('.')[0] ]\n",
        "    \n",
        "  if include_custom:\n",
        "\n",
        "    custom_parents = get_custom_parents(project_name)\n",
        "\n",
        "    for sample_id in custom_parents:\n",
        "      if custom_parents[sample_id] == parent_sample_id:\n",
        "        child_ids += [ sample_id ]        \n",
        "\n",
        "  # print(f'Children of {parent_sample_id}: {child_ids}')\n",
        "\n",
        "  return child_ids\n",
        "\n",
        "def get_custom_parents(project_name, force_reload=False):\n",
        "\n",
        "  global base_path, custom_parents\n",
        "  \n",
        "  if not custom_parents or custom_parents['project_name'] != project_name or force_reload:\n",
        "    print('Loading custom parents...')\n",
        "    custom_parents = {}\n",
        "    filename = f'{base_path}/{project_name}/{project_name}-parents.yaml'\n",
        "    if os.path.exists(filename):\n",
        "      print(f'Found {filename}')\n",
        "      with open(filename) as f:\n",
        "        loaded_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        print(f'Loaded as {loaded_dict}')\n",
        "        # Add project_name to the beginning of every key and value in the dictionary\n",
        "        custom_parents = { f'{project_name}-{k}': f'{project_name}-{v}' for k, v in loaded_dict.items() }\n",
        "\n",
        "    custom_parents['project_name'] = project_name\n",
        "    \n",
        "    print(f'Custom parents: {custom_parents}')\n",
        "\n",
        "  return custom_parents\n",
        "\n",
        "def get_first_free_index(project_name, parent_sample_id = None):\n",
        "  print(f'Getting first free index for {project_name}, parent {parent_sample_id}')\n",
        "  child_ids = get_children(project_name, parent_sample_id, include_custom=False)\n",
        "  print(f'Child ids: {child_ids}')\n",
        "  # child_indices = [ int(child_id.split('-')[-1]) for child_id in child_ids ]\n",
        "  child_indices = []\n",
        "  for child_id in child_ids:\n",
        "    suffix = child_id.split('-')[-1]\n",
        "    # If not an integer, ignore\n",
        "    if suffix.isdigit():\n",
        "      child_indices += [ int(suffix) ]\n",
        "  \n",
        "  first_free_index = max(child_indices) + 1 if child_indices and max(child_indices) >= 0 else 1\n",
        "  print(f'First free index: {first_free_index}')\n",
        "\n",
        "  return first_free_index\n",
        "\n",
        "def on_load( href, query_string, error_message ):\n",
        "\n",
        "  if error_message:\n",
        "    print(f'Please open this app in a separate browser tab: {href}')\n",
        "    print(f'Error message from the client (for debugging only; you can ignore this): {error_message}')\n",
        "\n",
        "    return {\n",
        "      UI.separate_tab_warning: gr.update(\n",
        "        visible = True,\n",
        "      ),\n",
        "      UI.separate_tab_link: href,\n",
        "      UI.main_window: gr.update(\n",
        "        visible = False,\n",
        "      ),\n",
        "    }\n",
        "\n",
        "\n",
        "  projects = get_projects()\n",
        "\n",
        "  def get_last_project():\n",
        "    if len(projects) == 1:\n",
        "      return 'CREATE NEW'\n",
        "\n",
        "    elif os.path.isfile(f'{base_path}/settings.yaml'):\n",
        "      with open(f'{base_path}/settings.yaml', 'r') as f:\n",
        "        settings = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        print(f'Loaded settings: {settings}')\n",
        "        if 'last_project' in settings:\n",
        "          print(f'Last project: {settings[\"last_project\"]}')\n",
        "          return settings['last_project']\n",
        "        else:\n",
        "          print('No last project found.')\n",
        "          return projects[0]\n",
        "  \n",
        "  # If there is a query string, it will be of the form project_name-sample_id or project_name\n",
        "  if query_string:\n",
        "    print(f'Query string: {query_string}')\n",
        "    if '-' in query_string:\n",
        "      project_name, sample_id = re.match('^(.*?)-(.*)$', query_string).groups()\n",
        "      sample_id = f'{project_name}-{sample_id}'\n",
        "      print(f'Routed to project {project_name} and sample {sample_id}')\n",
        "    else:\n",
        "      project_name = query_string\n",
        "      sample_id = None\n",
        "      print(f'Routed to project {project_name}')\n",
        "  else:\n",
        "    project_name = get_last_project()\n",
        "    sample_id = None\n",
        "\n",
        "  return {\n",
        "    UI.project_name: gr.update(\n",
        "      choices = projects,\n",
        "      value = project_name,\n",
        "    ),\n",
        "    UI.routed_sample_id: sample_id,\n",
        "    UI.artist: gr.update(\n",
        "      choices = get_list('artist'),\n",
        "    ),\n",
        "    UI.genre: gr.update(\n",
        "      choices = get_list('genre'),\n",
        "    ),\n",
        "    UI.getting_started_column: gr.update(\n",
        "      visible = len(projects) == 1\n",
        "    ),\n",
        "    UI.separate_tab_warning: gr.update(\n",
        "      visible = False\n",
        "    ),\n",
        "    UI.main_window: gr.update(\n",
        "      visible = True\n",
        "    ),\n",
        "    UI.genre_for_upsampling_left_channel: gr.update(\n",
        "      choices = get_list('genre')\n",
        "    ),\n",
        "    UI.genre_for_upsampling_center_channel: gr.update(\n",
        "      choices = get_list('genre'),\n",
        "    ),\n",
        "    UI.genre_for_upsampling_right_channel: gr.update(\n",
        "      choices = get_list('genre'),\n",
        "    ),\n",
        "  }\n",
        "\n",
        "lists = {}\n",
        "def get_list(what):\n",
        "  items = []\n",
        "  # print(f'Getting {what} list...')\n",
        "  # If list already exists, return it\n",
        "  if what in lists:\n",
        "    # print(f'{what} list already exists.')\n",
        "    return lists[what]\n",
        "  else:\n",
        "    with urllib.request.urlopen(f'https://raw.githubusercontent.com/openai/jukebox/master/jukebox/data/ids/v2_{what}_ids.txt') as f:\n",
        "      for line in f:\n",
        "        item = line.decode('utf-8').split(';')[0]\n",
        "        item = item.replace('_', ' ').title()\n",
        "        items.append(item)\n",
        "    items.sort()\n",
        "    print(f'Loaded {len(items)} {what}s.')\n",
        "    lists[what] = items\n",
        "  return items\n",
        "\n",
        "def get_parent(project_name, sample_id):\n",
        "\n",
        "  global base_path\n",
        "  \n",
        "  custom_parents = get_custom_parents(project_name)\n",
        "\n",
        "  if sample_id in custom_parents:\n",
        "    return custom_parents[sample_id]\n",
        "\n",
        "  # Remove the project name and first dash from the sample id\n",
        "  path = sample_id[ len(project_name) + 1: ].split('-')\n",
        "  parent_sample_id = '-'.join([ project_name, *path[:-1] ]) if len(path) > 1 else None\n",
        "  # print(f'Parent of {sample_id}: {parent_sample_id}')\n",
        "  return parent_sample_id\n",
        "\n",
        "def get_prefix(project_name, parent_sample_id):\n",
        "  return f'{parent_sample_id or project_name}-'\n",
        "\n",
        "def get_samples(project_name, leafs_only):\n",
        "\n",
        "  choices = []\n",
        "  for filename in os.listdir(f'{base_path}/{project_name}'):\n",
        "    if re.match(r'.*\\.zs?$', filename):\n",
        "      id = filename.split('.')[0]\n",
        "      if leafs_only and len( get_children(project_name, id) ) > 0:\n",
        "        continue\n",
        "      choices += [ id ]\n",
        "  \n",
        "  # Sort by id, in descending order\n",
        "  choices.sort(reverse = True)\n",
        "  \n",
        "  return choices\n",
        "\n",
        "def get_projects(include_new = True):\n",
        "  \n",
        "  global base_path\n",
        "\n",
        "  # print(f'Getting project list for {base_path}...')\n",
        "\n",
        "  project_names = []\n",
        "  for folder in os.listdir(base_path):\n",
        "    if os.path.isdir(base_path+'/'+folder) and not folder.startswith('_'):\n",
        "      project_names.append(folder)\n",
        "  # Sort project names alphabetically\n",
        "  project_names.sort()\n",
        "\n",
        "  print(f'Found {len(project_names)} projects: {project_names}')\n",
        "\n",
        "  if include_new:\n",
        "    project_names = ['CREATE NEW', *project_names]\n",
        "\n",
        "  return project_names\n",
        "\n",
        "def get_project_name_from_sample_id(sample_id):\n",
        "  projects = get_projects(include_new = False)\n",
        "  # Find a project that matches the sample id, which is [project name]-[rest of sample id]\n",
        "  for project_name in projects:\n",
        "    if sample_id.startswith(f'{project_name}-'):\n",
        "      return project_name\n",
        "\n",
        "def get_siblings(project_name, sample_id):\n",
        "\n",
        "  return get_children(project_name, get_parent(project_name, sample_id))\n",
        "\n",
        "def is_new(project_name):\n",
        "  return project_name == 'CREATE NEW' or not project_name\n",
        "  \n",
        "def get_project(project_name, routed_sample_id):\n",
        "\n",
        "  global base_path, loaded_settings\n",
        "\n",
        "  is_this_new = is_new(project_name)\n",
        "\n",
        "  # Start with default values for project settings\n",
        "  settings_out_dict = {\n",
        "    UI.artist: 'Unknown',\n",
        "    UI.genre: 'Unknown',\n",
        "    UI.lyrics: '',\n",
        "    UI.generation_length: 1,\n",
        "    UI.temperature: 0.98,\n",
        "    UI.n_samples: 2,\n",
        "    UI.sample_tree: None,\n",
        "    UI.genre_for_upsampling_left_channel: 'Unknown',\n",
        "    UI.genre_for_upsampling_center_channel: 'Unknown',\n",
        "    UI.genre_for_upsampling_right_channel: 'Unknown',\n",
        "  }\n",
        "\n",
        "  samples = []\n",
        "  sample = None\n",
        "\n",
        "  # If not new, load the settings from settings.yaml in the project folder, if it exists\n",
        "  if not is_this_new:\n",
        "\n",
        "    print(f'Loading settings for {project_name}...')\n",
        "\n",
        "    project_path = f'{base_path}/{project_name}'\n",
        "    hps.name = project_path\n",
        "    settings_path = f'{project_path}/{project_name}.yaml'\n",
        "    if os.path.isfile(settings_path):\n",
        "      with open(settings_path, 'r') as f:\n",
        "        loaded_settings = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        print(f'Loaded settings for {project_name}: {loaded_settings}')\n",
        "\n",
        "        # Go through all the settings and set the value for settings_out_dict where the key is the element itself\n",
        "        for key, value in loaded_settings.items():\n",
        "          if key in UI.inputs_by_name and UI.inputs_by_name[key] in UI.project_settings:\n",
        "\n",
        "            input = UI.inputs_by_name[key]\n",
        "\n",
        "            # If the value is an integer (i) but the element is an instance of gr.components.Radio or gr.components.Dropdown, take the i-th item from the choices\n",
        "            if isinstance(value, int) and isinstance(input, (gr.components.Radio, gr.components.Dropdown)):\n",
        "              print(f'Converting {key} value {value} to {input.choices[value]}')\n",
        "              value = input.choices[value]\n",
        "            \n",
        "            settings_out_dict[getattr(UI, key)] = value\n",
        "\n",
        "          else:\n",
        "            print(f'Warning: {key} is not a valid project setting')\n",
        "\n",
        "    # Write the last project name to settings.yaml\n",
        "    with open(f'{base_path}/settings.yaml', 'w') as f:\n",
        "      print(f'Saving {project_name} as last project...')\n",
        "      yaml.dump({'last_project': project_name}, f)\n",
        "      print('Saved to settings.yaml')\n",
        "    \n",
        "    settings_out_dict[ UI.getting_started_column ] = gr.update(\n",
        "      visible = False\n",
        "    )\n",
        "\n",
        "    samples = get_samples(project_name, settings_out_dict[ UI.show_leafs_only ] if UI.show_leafs_only in settings_out_dict else False)\n",
        "\n",
        "    sample = routed_sample_id or (\n",
        "      (\n",
        "        settings_out_dict[ UI.sample_tree ] or samples[0] \n",
        "      ) if len(samples) > 0 else None\n",
        "    )\n",
        "\n",
        "    settings_out_dict[ UI.sample_tree ] = gr.update(\n",
        "      choices = samples,\n",
        "      value = sample \n",
        "    )\n",
        "\n",
        "\n",
        "  return {\n",
        "    UI.create_project_box: gr.update( visible = is_this_new ),\n",
        "    UI.settings_box: gr.update( visible = not is_this_new ),\n",
        "    UI.workspace_column: gr.update( visible = not is_this_new  ),\n",
        "    UI.sample_box: gr.update( visible = sample is not None ),\n",
        "    UI.first_generation_row: gr.update( visible = len(samples) == 0 ),\n",
        "    UI.sample_tree_row: gr.update( visible = len(samples) > 0 ),\n",
        "    **settings_out_dict\n",
        "  }\n",
        "\n",
        "def get_sample_filename(project_name, sample_id, cut_out, last_n_sec, upsample_rendering, combine_levels):\n",
        "    \n",
        "    filename = f'{base_path}/{project_name}/rendered/{sample_id} '\n",
        "\n",
        "    # Add cutout/preview suffixes, replacing dots with underscores (to avoid confusion with file extensions)\n",
        "\n",
        "    def replace_dots_with_underscores(number):\n",
        "      return str(number).replace('.', '_')\n",
        "\n",
        "    if cut_out:\n",
        "      filename += f'cut {replace_dots_with_underscores(cut_out)} '\n",
        "    if last_n_sec:\n",
        "      filename += f'last {replace_dots_with_underscores(last_n_sec)} '\n",
        "    \n",
        "    # Add lowercase of upsample rendering option\n",
        "    if upsample_rendering:\n",
        "      filename += f'r{upsample_rendering} '\n",
        "    \n",
        "    if combine_levels:\n",
        "      filename += f'combined '\n",
        "    \n",
        "    return filename\n",
        "\n",
        "def get_sample(project_name, sample_id, cut_out='', last_n_sec=None, upsample_rendering=4, combine_levels=True, force_reload=False):\n",
        "\n",
        "  global hps\n",
        "\n",
        "  print(f'Loading sample {sample_id}')\n",
        "\n",
        "  filename = get_sample_filename(project_name, sample_id, cut_out, last_n_sec, upsample_rendering, combine_levels)\n",
        "  filename_without_hash = filename\n",
        "\n",
        "  # Add a hash (8 characters of md5) of the corresponding z file (so that we can detect if the z file has changed and hence we need to re-render)\n",
        "  filename += f'{hashlib.md5(open(f\"{base_path}/{project_name}/{sample_id}.z\", \"rb\").read()).hexdigest()[:8]} '\n",
        "\n",
        "\n",
        "  print(f'Checking if {filename} is cached...')\n",
        "\n",
        "  # Make sure all 3 of wav, mp3 and yaml exist\n",
        "  if not force_reload:\n",
        "    for ext in [ 'wav', 'mp3', 'yaml' ]:\n",
        "      if not os.path.isfile(f'{filename}.{ext}'):\n",
        "        force_reload = True\n",
        "        break\n",
        "\n",
        "  if force_reload:\n",
        "\n",
        "    print('Nope, rendering...')\n",
        "\n",
        "    # First, let's delete any old files that have the same name but a different hash (because these are now obsolete)\n",
        "    for f in glob.glob(f'{filename_without_hash}.*'):\n",
        "      print(f'(Deleting now-obsolete cached file {f})')\n",
        "      os.remove(f)\n",
        "\n",
        "    if last_n_sec:\n",
        "      last_n_sec = -last_n_sec\n",
        "    # (Because get_audio, called below, accepts \"preview_sec\", whose positive value means \"preview the first n seconds\", but we want to preview the last n seconds)\n",
        "\n",
        "    wav, total_audio_length, upsampled_lengths = get_audio(project_name, sample_id, cut_out, last_n_sec, None, upsample_rendering, combine_levels)\n",
        "    # (level is None, which means \"the highest level that is available\", i.e. 2)\n",
        "\n",
        "    if not os.path.exists(os.path.dirname(filename)):\n",
        "      os.makedirs(os.path.dirname(filename))\n",
        "\n",
        "    librosa.output.write_wav(f'{filename}.wav', np.asfortranarray(wav), hps.sr)\n",
        "\n",
        "    # Add metadata (total audio length, upsampled lengths) to a yaml with the same name as the wav file\n",
        "    with open(f'{filename}.yaml', 'w') as f:\n",
        "      yaml.dump({\n",
        "        'total_audio_length': total_audio_length,\n",
        "        'upsampled_lengths': upsampled_lengths\n",
        "      }, f)\n",
        "\n",
        "    # Convert to mp3\n",
        "    subprocess.run(['ffmpeg', '-y', '-i', f'{filename}.wav', '-acodec', 'libmp3lame', '-ab', '320k', f'{filename}.mp3'])\n",
        "\n",
        "    # If there are more than 30 files in the rendered folder (i.e. more than 10 samples), delete the ones older than 1 day\n",
        "    file_count_limit = 30\n",
        "    files = glob.glob(f'{base_path}/{project_name}/rendered/*')\n",
        "    if len(files) > file_count_limit:\n",
        "      removed_count = 0\n",
        "      failed_count = 0\n",
        "      for f in files:\n",
        "        try:\n",
        "          if datetime.now() - datetime.fromtimestamp(os.path.getmtime(f)) > timedelta(days=1):\n",
        "            os.remove(f)\n",
        "            removed_count += 1\n",
        "        except Exception as e:\n",
        "          print(f'Could not remove {f}: {e}')\n",
        "          failed_count += 1\n",
        "      print(f'Deleted {removed_count} of {removed_count + failed_count} old files')\n",
        "        \n",
        "  else:\n",
        "    print('Yep, using it.')\n",
        "    wav = None\n",
        "\n",
        "    # Load metadata\n",
        "    with open(f'{filename}.yaml', 'r') as f:\n",
        "      metadata = yaml.load(f, Loader=yaml.FullLoader)\n",
        "      total_audio_length = metadata['total_audio_length']\n",
        "      upsampled_lengths = metadata['upsampled_lengths']\n",
        "      print(f'(Also loaded metadata: {metadata})')\n",
        "\n",
        "  chunk_filenames = []\n",
        "\n",
        "  # If the mp3 size is > certain sie, we'll need to send it back in chunks, so we divide the mp3 into as many chunks as needed\n",
        "  file_size = os.path.getsize(f'{filename}.mp3')\n",
        "  file_limit = 300000\n",
        "  if file_size > file_limit:\n",
        "    print(f'MP3 file size is {file_size} bytes, splitting into chunks...')\n",
        "    file_content = open(f'{filename}.mp3', 'rb').read()\n",
        "    for i in range(0, file_size, file_limit):\n",
        "      # Place the chunk file in tmp/[filename without path] [range].mp3_chunk\n",
        "      # Create the tmp folder if it doesn't exist\n",
        "      if not os.path.exists(f'tmp'):        \n",
        "        os.makedirs(f'tmp')\n",
        "      chunk_filename = f'tmp/{os.path.basename(filename)}{i}-{i+file_limit} .mp3_chunk'\n",
        "      with open(chunk_filename, 'wb') as f:\n",
        "        f.write(file_content[i:i+file_limit])\n",
        "        print(f'Wrote bytes {i}-{i+file_limit} to {chunk_filename}')\n",
        "      chunk_filenames.append(chunk_filename)\n",
        "  else:\n",
        "    chunk_filenames = [f'{filename}.mp3']\n",
        "  \n",
        "  print(f'Files to send: {chunk_filenames}')\n",
        "\n",
        "  return {\n",
        "    UI.current_chunks: chunk_filenames,\n",
        "    UI.total_audio_length: total_audio_length,\n",
        "    UI.go_to_children_button: gr.update(\n",
        "      visible = len(get_children(project_name, sample_id)) > 0\n",
        "    ),\n",
        "    UI.go_to_parent_button: gr.update(\n",
        "      visible = get_parent(project_name, sample_id) is not None\n",
        "    ),\n",
        "    UI.sample_box: gr.update(\n",
        "      visible = True\n",
        "    ),\n",
        "    UI.upsampled_lengths: ','.join([str(length) for length in upsampled_lengths]),\n",
        "    # Random number for picked sample updated flag\n",
        "    UI.picked_sample_updated: random.random(),\n",
        "  }\n",
        "\n",
        "def get_sibling_samples(project_name, sample_id, cut_out, last_n_sec, upsample_rendering, combine_levels):\n",
        "  print(f'Updating sibling samples for {sample_id}...')\n",
        "  sibling_files = []\n",
        "  for sibling_id in get_siblings(project_name, sample_id):\n",
        "    if sibling_id == sample_id:\n",
        "      continue\n",
        "    sibling_sample = get_sample(project_name, sibling_id, cut_out, last_n_sec, upsample_rendering, combine_levels)\n",
        "    sibling_sample_files = sibling_sample[UI.current_chunks]\n",
        "    # breakpoint()\n",
        "    print(f'Adding sibling {sibling_id} with files {sibling_sample_files}')\n",
        "    sibling_files.extend(sibling_sample_files)\n",
        "    print(f'Totally {len(sibling_files)} sibling files')\n",
        "  return {\n",
        "    UI.sibling_chunks: sibling_files\n",
        "  }\n",
        "\n",
        "def refresh_siblings(project_name, sample_id):\n",
        "  \n",
        "  if not sample_id:\n",
        "    return {\n",
        "      UI.picked_sample: HIDE\n",
        "    }\n",
        "\n",
        "  # print(f'Getting siblings for {sample_id}...')\n",
        "  siblings = get_siblings(project_name, sample_id)\n",
        "  # print(f'Siblings for {sample_id}: {siblings}')\n",
        "  return gr.update(\n",
        "    choices = siblings,\n",
        "    value = sample_id,\n",
        "    visible = len(siblings) > 1\n",
        "  )\n",
        "\n",
        "def rename_sample(project_name, old_sample_id, new_sample_id, show_leafs_only):\n",
        "\n",
        "  if not re.match(r'^[a-zA-Z0-9-]+$', new_sample_id):\n",
        "    raise ValueError('Sample ID must be alphanumeric and dashes only')\n",
        "\n",
        "  new_sample_id = f'{project_name}-{new_sample_id}'\n",
        "\n",
        "  print(f'Renaming {old_sample_id} to {new_sample_id}')\n",
        "\n",
        "  custom_parents = get_custom_parents(project_name)\n",
        "  print(f'Custom parents: {custom_parents}')\n",
        "  custom_parents[new_sample_id] = get_parent(project_name, old_sample_id)\n",
        "  print(f'Added {new_sample_id} -> {custom_parents[new_sample_id]} to custom parents')\n",
        "  if old_sample_id in custom_parents:\n",
        "    del custom_parents[old_sample_id]\n",
        "    print(f'Removed {old_sample_id} from custom parents')\n",
        "\n",
        "  # Find all samples that have this sample as a custom parent and update them\n",
        "  for child, parent in custom_parents.items():\n",
        "    if parent == old_sample_id:\n",
        "      custom_parents[child] = new_sample_id\n",
        "      print(f'Updated {child} -> {new_sample_id} in custom parents')\n",
        "  \n",
        "  print(f'Final custom parents: {custom_parents}')\n",
        "  \n",
        "  # Save the new custom parents\n",
        "  with open(f'{base_path}/{project_name}/{project_name}-parents.yaml', 'w') as f:\n",
        "    # Dump everything but the \"project_name\" key and remove the \"project_name-\" prefix\n",
        "    custom_parents_to_save = {\n",
        "      k[len(project_name)+1:]: v[len(project_name)+1:] for k, v in custom_parents.items() if k != 'project_name'\n",
        "    }\n",
        "    print(f'Writing: {custom_parents_to_save}')\n",
        "    yaml.dump(custom_parents_to_save, f)\n",
        "    print('Done.')\n",
        "\n",
        "  # Find all files in the project directory that start with the old sample ID followed by either a dash or a dot and rename them\n",
        "  for filename in os.listdir(f'{base_path}/{project_name}'):\n",
        "    if re.match(rf'^{old_sample_id}[-.]', filename):\n",
        "      new_filename = filename.replace(old_sample_id, new_sample_id)\n",
        "      print(f'Renaming {filename} to {new_filename}')\n",
        "      os.rename(f'{base_path}/{project_name}/{filename}', f'{base_path}/{project_name}/{new_filename}')\n",
        "    \n",
        "  return gr.update(\n",
        "    choices = get_samples(project_name, show_leafs_only),\n",
        "    value = new_sample_id\n",
        "  )\n",
        "\n",
        "def save_project(project_name, *project_input_values):\n",
        "\n",
        "  if is_new(project_name):\n",
        "    return\n",
        "\n",
        "  # print(f'Saving settings for {project_name}...')\n",
        "  # print(f'Project input values: {project_input_values}')\n",
        "\n",
        "  # Go through all UI attributes and add the ones that are in the project settings to a dictionary\n",
        "  settings = {}\n",
        "\n",
        "  for i in range(len(UI.project_settings)):\n",
        "    settings[UI.input_names[UI.project_settings[i]]] = project_input_values[i]\n",
        "  \n",
        "  # print(f'Settings: {settings}')\n",
        "\n",
        "  # If the settings are different from the loaded settings, save them to the project folder\n",
        "\n",
        "  if settings != loaded_settings:\n",
        "\n",
        "    with open(f'{base_path}/{project_name}/{project_name}.yaml', 'w') as f:\n",
        "      yaml.dump(settings, f)\n",
        "      print(f'Saved settings to {base_path}/{project_name}/{project_name}.yaml: {settings}')\n",
        "  \n",
        "  # else:\n",
        "  #   print('Settings are the same as loaded settings, not saving.')\n",
        "\n",
        "def seconds_to_tokens(sec, level = 2):\n",
        "\n",
        "  global hps, raw_to_tokens, chunk_size\n",
        "\n",
        "  tokens = sec * hps.sr // raw_to_tokens\n",
        "  tokens = ( (tokens // chunk_size) + 1 ) * chunk_size\n",
        "\n",
        "  # For levels 1 and 0, multiply by 4 and 16 respectively\n",
        "  tokens *= 4 ** (2 - level)\n",
        "\n",
        "  return int(tokens)\n",
        "\n",
        "def start_upsampling(project_name, sample_id, artist, lyrics, genre_left, genre_center, genre_right, kill_runtime_once_done=False):\n",
        "\n",
        "  global hps, top_prior, priors\n",
        "\n",
        "  genres = [genre_left, genre_center, genre_right]\n",
        "\n",
        "  print(f'Starting upsampling for {sample_id}, artist: {artist}, lyrics: {lyrics}, genres: {genres}')\n",
        "\n",
        "  Upsampling.project = project_name\n",
        "  Upsampling.sample_id = sample_id\n",
        "\n",
        "  Upsampling.running = True\n",
        "  Upsampling.status_markdown = \"Loading the upsampling models...\"\n",
        "\n",
        "  Upsampling.level = 1\n",
        "\n",
        "  Upsampling.kill_runtime_once_done = kill_runtime_once_done\n",
        "\n",
        "  print(f'Upsampling {sample_id} with genres {genres}')\n",
        "  filename = f'{base_path}/{project_name}/{sample_id}.z'\n",
        "\n",
        "  Upsampling.zs = t.load(filename)\n",
        "\n",
        "  # Get the level 0/1 zs of the first upsampled ancestor (so we can continue upsampling from where we left off)\n",
        "  for i in range( len(Upsampling.zs) ):\n",
        "    if i == 2:\n",
        "      Upsampling.zs[i] = Upsampling.zs[i][0].repeat(3, 1)\n",
        "    elif Upsampling.zs[i].shape[0] != 3:\n",
        "      # If there are no upsampled ancestors, replace with an empty tensor\n",
        "      first_upsampled_ancestor = get_first_upsampled_ancestor_zs(project_name, sample_id)\n",
        "      if not first_upsampled_ancestor:\n",
        "        print(f'No upsampled ancestors found for {sample_id}, using empty tensors')\n",
        "        Upsampling.zs[i] = t.empty( (3, 0), dtype=t.int64 ).cuda()\n",
        "      else:\n",
        "        print(f'Using first upsampled ancestor zs for {sample_id}')\n",
        "        Upsampling.zs[i] = first_upsampled_ancestor[i]\n",
        "    \n",
        "  print(f'Final z shapes: {[ z.shape for z in Upsampling.zs ]}')\n",
        "\n",
        "  # We also need to create new labels from the metas with the genres replaced accordingly\n",
        "  Upsampling.metas = [ dict(\n",
        "    artist = artist,\n",
        "    genre = genre,\n",
        "    total_length = hps.sample_length,\n",
        "    offset = 0,\n",
        "    lyrics = lyrics,\n",
        "  ) for genre in genres ]\n",
        "\n",
        "  if not Upsampling.labels:\n",
        "\n",
        "    # Search for labels under [project_name]/[project_name].labels\n",
        "    labels_path = f'{base_path}/{project_name}/{project_name}.labels'\n",
        "\n",
        "    should_reload_labels = True\n",
        "\n",
        "    if os.path.exists(labels_path):\n",
        "      Upsampling.labels, stored_metas = t.load(labels_path)\n",
        "      print(f'Loaded labels from {labels_path}')\n",
        "      # Make sure the metas match\n",
        "      if stored_metas == Upsampling.metas:\n",
        "        print('Metas match, not reloading labels')\n",
        "        should_reload_labels = False\n",
        "      else:\n",
        "        print(f'Metas do not match, reloading labels. Stored metas: {stored_metas}, current metas: {Upsampling.metas}')\n",
        "    \n",
        "    if should_reload_labels:\n",
        "\n",
        "      try:\n",
        "        assert top_prior\n",
        "      except:\n",
        "        load_top_prior()\n",
        "      \n",
        "      Upsampling.labels = top_prior.labeller.get_batch_labels(Upsampling.metas, 'cuda')\n",
        "      print('Calculated new labels from top prior')\n",
        "\n",
        "      t.save([ Upsampling.labels, Upsampling.metas ], labels_path)\n",
        "      print(f'Saved labels and metas to {labels_path}')\n",
        "\n",
        "      # We need to delete the top_prior object and empty the cache, otherwise we'll get an OOM error\n",
        "      del top_prior\n",
        "      empty_cache()\n",
        "\n",
        "  labels = Upsampling.labels\n",
        "\n",
        "  upsamplers = [ make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1] ]\n",
        "  \n",
        "  if type(labels)==dict:\n",
        "    labels = [ prior.labeller.get_batch_labels(Upsampling.metas, 'cuda') for prior in upsamplers ] + [ labels ]\n",
        "    print('Converted labels to list')\n",
        "    # Not sure why we need to do this -- I copied this from another notebook.\n",
        "  \n",
        "  Upsampling.labels = labels\n",
        "  \n",
        "  # Create a backup of the original file, in case something goes wrong\n",
        "  bak_filename = f'{filename}.{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.bak'\n",
        "  shutil.copy(filename, f'{bak_filename}')\n",
        "  print(f'Created backup of {filename} as {bak_filename}')\n",
        "\n",
        "  t.save(Upsampling.zs, filename)\n",
        "\n",
        "  Upsampling.params = [\n",
        "    dict(temp=0.99, fp16=True, max_batch_size=16, chunk_size=32),\n",
        "    dict(temp=0.99, fp16=True, max_batch_size=16, chunk_size=32),\n",
        "    None\n",
        "  ]\n",
        "  \n",
        "  Upsampling.hps = hps\n",
        "\n",
        "  # Set hps.n_samples to 3, because we need 3 samples for each level\n",
        "  Upsampling.hps.n_samples = 3\n",
        "\n",
        "  # Set hps.sample_length to the actual length of the sample\n",
        "  Upsampling.hps.sample_length = Upsampling.zs[2].shape[1] * raw_to_tokens\n",
        "\n",
        "  # Set hps.name to our project directory\n",
        "  Upsampling.hps.name = f'{base_path}/{project_name}'\n",
        "\n",
        "  Upsampling.priors = [*upsamplers, None]\n",
        "  Upsampling.zs = upsample(Upsampling.zs, Upsampling.labels, Upsampling.params, Upsampling.priors, Upsampling.hps)\n",
        "\n",
        "def request_to_stop_upsampling():\n",
        "  if Upsampling.running:\n",
        "    print('Stopping upsampling...')\n",
        "    Upsampling.stop = True\n",
        "  else:\n",
        "    print('No upsampling running')\n",
        "\n",
        "def is_ancestor(project_name, potential_ancestor, potential_descendant):\n",
        "  parent = get_parent(project_name, potential_descendant)\n",
        "  if parent == potential_ancestor:\n",
        "    return True\n",
        "  elif parent:\n",
        "    return is_ancestor(project_name, potential_ancestor, parent)\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def restart_upsampling(sample_id, even_if_no_labels = False, even_if_not_ancestor = False):\n",
        "\n",
        "  global sample_id_to_restart_upsampling_with\n",
        "\n",
        "  get_custom_parents(Upsampling.project, force_reload = True)\n",
        "\n",
        "  if Upsampling.running:\n",
        "    print('Upsampling is already running; stopping & waiting for it to finish to restart')\n",
        "    request_to_stop_upsampling()\n",
        "    sample_id_to_restart_upsampling_with = sample_id\n",
        "    return\n",
        "\n",
        "  assert not Upsampling.running, 'Upsampling is already running. Use stop_upsampling() to stop it and wait for the current window to finish.'\n",
        "\n",
        "  assert Upsampling.labels or even_if_no_labels, 'Upsampling.labels is empty, cannot restart. If you want to restart anyway, set even_if_no_labels to True.'\n",
        "  if not Upsampling.labels:\n",
        "    load_top_prior()\n",
        "    # (We deleted the top_prior object in start_upsampling, so we need to reload it to recalculate the labels)\n",
        "\n",
        "  assert even_if_not_ancestor or is_ancestor(Upsampling.project, Upsampling.sample_id, sample_id), 'Cannot restart upsampling with a sample that is not a descendant of the currently upsampled sample. If you really want to do this, set even_if_not_ancestor to True.'\n",
        "\n",
        "  start_upsampling(Upsampling.project, sample_id, Upsampling.metas[0]['artist'], Upsampling.metas[0]['lyrics'], *[ meta['genre'] for meta in Upsampling.metas ])\n",
        "  # (Note that the metas don't do anything here, as we're already using the calculated labels. Keeping for future cases where we might want to restart with different metas.)\n",
        "  print('Warning: Using the same labels as before. If you want to restart with different labels, you need to set Upsampling.labels to None before calling restart_upsampling.')\n",
        "\n",
        "def set_keep_upsampling_after_restart():\n",
        "  global keep_upsampling_after_restart\n",
        "\n",
        "  keep_upsampling_after_restart = True\n",
        "\n",
        "def tokens_to_seconds(tokens, level = 2):\n",
        "\n",
        "  global hps, raw_to_tokens\n",
        "\n",
        "  return tokens * raw_to_tokens / hps.sr / 4 ** (2 - level)\n",
        "\n",
        "def cut_z(z, specs, level):\n",
        "  # possible specs:\n",
        "  # start-end -- cuts out the specified range (in seconds), either can be omitted to cut from the start or to the end, the dash can be omitted to cut from the specified time to the end\n",
        "  # start-end+sample_id@start-end -- takes the specified range from the specified sample and adds it instead of the cut-out range\n",
        "  # start-end+start-end -- same, but takes the specified range from the current sample\n",
        "  # +sample_id@start-end -- adds the specified range from the specified sample to the end of the current sample\n",
        "  # +start-end -- keeps just the specified range from the current sample (i.e. the opposite of start-end)\n",
        "  # Any whitespaces are ignored\n",
        "  # All of these can be combined with a comma to cut out multiple ranges\n",
        "  specs = specs.replace(' ', '')\n",
        "\n",
        "  print(f'z shape before cut: {z.shape}')\n",
        "\n",
        "  for spec in specs.split(','):\n",
        "\n",
        "    remove, add = spec.split('+') if '+' in spec else (spec, None)    \n",
        "\n",
        "    out_z = z[:, :0]\n",
        "\n",
        "    if remove:\n",
        "\n",
        "      # The removed interval is a string of format 'start-end' or just 'start'. In the latter case, end is assumed to be the end of the sample\n",
        "      remove_start, remove_end = remove.split('-') if '-' in remove else (remove, None)\n",
        "\n",
        "      # Hidden spec: if either start or end start with a '<', the corresponding value is taken from the end of the sample (i.e. we just negate the value, i.e. replace '<' with '-')\n",
        "      # (\"<\" because \"-\" is already used for specifying the interval. It also looks like a backwards arrow which is a good visual cue for this)\n",
        "      remove_start, remove_end = [ s and s.replace('<', '-') for s in (remove_start, remove_end) ]\n",
        "\n",
        "      # If start or end is empty, it means the interval starts at the beginning or ends at the end\n",
        "      remove_start = seconds_to_tokens(float(remove_start), level) if remove_start else 0\n",
        "\n",
        "      # If remove_start is more than the length of the sample, we just return an empty sample\n",
        "      # (We don't need to see the add part, because it's not going to be added to anything. The only exception is if no remove part is specified, but in that case this part of the code is not executed anyway)\n",
        "      if remove_start >= z.shape[1]:\n",
        "        print(f'Warning: remove_start ({remove_start}) is more than the length of the sample ({z.shape[1]}) for level {level}. Returning an empty sample.')\n",
        "        break\n",
        "\n",
        "      remove_end = seconds_to_tokens(float(remove_end), level) if remove_end else z.shape[1]\n",
        "      print(f'Cutting out {remove} (tokens {remove_start}-{remove_end})')\n",
        "\n",
        "      out_z = t.cat([out_z, z[:, :remove_start]], dim=1)\n",
        "      print(f'out_z shape: {out_z.shape}')\n",
        "\n",
        "    # For the added interval, both start and end are required (but sample_id is optional, and defaults to the current sample)\n",
        "    if add:\n",
        "      add_sample_id, add = add.split('@') if '@' in add else (None, add)\n",
        "      add_start, add_end = add.split('-')\n",
        "      add_start = seconds_to_tokens(float(add_start), level)\n",
        "      add_end = seconds_to_tokens(float(add_end), level)\n",
        "      print(f'Adding {add} (tokens {add_start}-{add_end}) from { add_sample_id or \"current sample\" }')\n",
        "\n",
        "      if add_sample_id:\n",
        "        add_z = get_zs(get_project_name_from_sample_id(add_sample_id), add_sample_id)[level]\n",
        "        # If no remove was specified, add the entire original sample (before we add the part from the other sample)\n",
        "        if not remove:\n",
        "          out_z = z\n",
        "      else:\n",
        "        add_z = z\n",
        "        # (In this case we don't add the original sample, because we just want to keep the specified range)\n",
        "      \n",
        "      out_z = t.cat([out_z, add_z[:, add_start:add_end]], dim=1)\n",
        "      print(f'out_z shape: {out_z.shape}')\n",
        "\n",
        "    if remove:\n",
        "      # If we added anything, and its end was after the end of the original sample, we break\n",
        "      # This is needed for cases when we add a part that hasn't been upsampled yet, so it would be added for the low-quality level, but not for the high-quality level (at least partially)\n",
        "      # In this case, we don't want to add the rest of the original sample, because then we would have a \"hole\" in the high-quality level, which will make further upsampling impossible\n",
        "      if add and add_end > z.shape[1]:\n",
        "        print(f'Warning: add_end ({add_end}) is more than the length of the sample ({z.shape[1]}) for level {level}. Breaking before adding the rest of the original sample.')\n",
        "        break\n",
        "\n",
        "      print(f'Adding the rest of the sample (tokens {remove_end}-{z.shape[1]})')\n",
        "      out_z = t.cat([out_z, z[:, remove_end:]], dim = 1)\n",
        "      print(f'out_z shape: {out_z.shape}')\n",
        "    \n",
        "    z = out_z\n",
        "\n",
        "  print(f'z shape after cut: {out_z.shape}')\n",
        "  return z\n",
        "\n",
        "def cut_zs(zs, specs):\n",
        "  return [ cut_z(zs[level], specs, level) for level in range(len(zs)) ]\n",
        "\n",
        "def cut_audio(project_name, sample_id, interval):\n",
        "  zs = get_zs(project_name, sample_id)\n",
        "  backup_zs(zs, project_name, sample_id)\n",
        "  zs = cut_zs(zs, interval)\n",
        "  save_zs(zs, project_name, sample_id)\n",
        "  return ''\n",
        "\n",
        "SHOW = gr.update( visible = True )\n",
        "HIDE = gr.update( visible = False )\n",
        "SHOW_OR_HIDE = lambda x: gr.update( visible = x )\n",
        "\n",
        "with gr.Blocks(\n",
        "  css = \"\"\"\n",
        "    .gr-button {\n",
        "      /* add margin to the button */\n",
        "      margin: 5px 5px 5px 5px;\n",
        "    }\n",
        "\n",
        "    #getting-started-column {\n",
        "      /* add a considerable margin to the left of the column */\n",
        "      margin-left: 20px;\n",
        "    }\n",
        "\n",
        "    #generation-progress {\n",
        "      /* gray, smaller font */\n",
        "      color: #777;\n",
        "      font-size: 0.8rem;\n",
        "    }\n",
        "\n",
        "    #audio-timeline {\n",
        "      /* hide for now */\n",
        "      display: none;\n",
        "    }\n",
        "\n",
        "\n",
        "  \"\"\",\n",
        "  title = f'Jukebox Web UI { GITHUB_SHA }{ \" (dev mode)\" if DEV_MODE else \"\" }',\n",
        ") as app:\n",
        "\n",
        "  UI.browser_timezone.render()\n",
        "\n",
        "  with UI.separate_tab_warning.render():\n",
        "\n",
        "    UI.separate_tab_link.render()\n",
        "\n",
        "    gr.Button('Click here to open the UI', variant = 'primary' ).click( inputs = UI.separate_tab_link, outputs = None, fn = None,\n",
        "      _js = \"link => window.open(link, '_blank')\"\n",
        "    )\n",
        "  \n",
        "  with UI.main_window.render():\n",
        "\n",
        "    with gr.Column( scale = 1 ):\n",
        "\n",
        "      UI.project_name.render().change(\n",
        "        inputs = [ UI.project_name, UI.routed_sample_id ],\n",
        "        outputs = [ \n",
        "          UI.create_project_box, UI.settings_box, *UI.project_settings, UI.getting_started_column, UI.workspace_column, UI.first_generation_row, \n",
        "          UI.sample_tree_row, UI.sample_box \n",
        "        ],\n",
        "        fn = get_project,\n",
        "        api_name = 'get-project'\n",
        "      )\n",
        "\n",
        "      with UI.create_project_box.render():\n",
        "\n",
        "        UI.new_project_name.render().blur(\n",
        "          inputs = UI.new_project_name,\n",
        "          outputs = UI.new_project_name,\n",
        "          fn = convert_name,\n",
        "        )\n",
        "\n",
        "        # When a project is created, create a subfolder for it and update the project list.\n",
        "        create_args = dict(\n",
        "          inputs = UI.new_project_name,\n",
        "          outputs = UI.project_name,\n",
        "          fn = create_project,\n",
        "        )\n",
        "\n",
        "        UI.new_project_name.submit( **create_args )\n",
        "        gr.Button('Create project').click( **create_args )\n",
        "\n",
        "      with UI.settings_box.render():\n",
        "\n",
        "        for component in UI.generation_params:\n",
        "          \n",
        "          # For artist, also add a search button and a randomize button\n",
        "          if component == UI.artist:\n",
        "\n",
        "            with gr.Row():\n",
        "\n",
        "              component.render()\n",
        "             \n",
        "              def filter_artists(filter):\n",
        "                \n",
        "                artists = get_list('artist')\n",
        "\n",
        "                if filter:\n",
        "                  artists = [ artist for artist in artists if filter.lower() in artist.lower() ]\n",
        "                  artist = artists[0]\n",
        "                else:\n",
        "                  # random artist\n",
        "                  artist = random.choice(artists)\n",
        "\n",
        "                return gr.update(\n",
        "                  choices = artists,\n",
        "                  value = artist\n",
        "                )\n",
        "\n",
        "              artist_filter = gr.Textbox(\n",
        "                label = 'ðŸ”',\n",
        "                placeholder = 'Empty for ðŸŽ²',\n",
        "              )\n",
        "\n",
        "              artist_filter.submit(\n",
        "                inputs = artist_filter,\n",
        "                outputs = UI.artist,\n",
        "                fn = filter_artists,\n",
        "                api_name = 'filter-artists'\n",
        "              )\n",
        "          \n",
        "          else:\n",
        "\n",
        "            component.render()\n",
        "        \n",
        "        for component in UI.project_settings:\n",
        "\n",
        "          # Whenever a project setting is changed, save all the settings to settings.yaml in the project folder\n",
        "          inputs = [ UI.project_name, *UI.project_settings ]\n",
        "\n",
        "          # Use the \"blur\" method if available, otherwise use \"change\"\n",
        "          handler_name = 'blur' if hasattr(component, 'blur') else 'change'\n",
        "          handler = getattr(component, handler_name)\n",
        "\n",
        "          handler(\n",
        "            inputs = inputs,\n",
        "            outputs = None,\n",
        "            fn = save_project,\n",
        "          )\n",
        "\n",
        "\n",
        "    with UI.getting_started_column.render():\n",
        "\n",
        "      # Load the getting started text from github (vzakharov/jukebox-webui/docs/getting-started.md) via urllib\n",
        "      with urllib.request.urlopen('https://raw.githubusercontent.com/vzakharov/jukebox-webui/main/docs/getting-started.md') as f:\n",
        "        getting_started_text = f.read().decode('utf-8')\n",
        "        gr.Markdown(getting_started_text)\n",
        "\n",
        "    with UI.workspace_column.render():\n",
        "\n",
        "      with gr.Tab('Workspace'):\n",
        "\n",
        "        with gr.Column():\n",
        "\n",
        "          with UI.first_generation_row.render():\n",
        "\n",
        "            with gr.Column():\n",
        "            \n",
        "              gr.Markdown(\"\"\"\n",
        "                To start composing, you need to generate the first batch of samples. You can:\n",
        "                \n",
        "                - Start from scratch by clicking the **Generate initial samples** button below, or\n",
        "                - Go to the **Prime** tab and convert your own audio to a sample.\n",
        "              \"\"\")\n",
        "\n",
        "              gr.Button('Generate initial samples', variant = \"primary\" ).click(\n",
        "                inputs = [ UI.project_name, UI.sample_tree, UI.show_leafs_only, *UI.generation_params ],\n",
        "                outputs = [ UI.sample_tree, UI.first_generation_row, UI.sample_tree_row, UI.generation_progress ],\n",
        "                fn = lambda *args: {\n",
        "                  **generate(*args),\n",
        "                  UI.first_generation_row: HIDE,\n",
        "                  UI.sample_tree_row: SHOW,\n",
        "                }\n",
        "              )\n",
        "\n",
        "          with UI.sample_tree_row.render():\n",
        "            \n",
        "            UI.routed_sample_id.render()\n",
        "            UI.sample_tree.render()\n",
        "\n",
        "            with gr.Column():\n",
        "\n",
        "              # with gr.Accordion('Options & stats', open=False ):\n",
        "\n",
        "              UI.show_leafs_only.render()\n",
        "\n",
        "              UI.show_leafs_only.change(\n",
        "                inputs = [ UI.project_name, UI.show_leafs_only ],\n",
        "                outputs = UI.sample_tree,\n",
        "                fn = lambda *args: gr.update( choices = get_samples(*args) ),\n",
        "              )\n",
        "\n",
        "                # UI.branch_sample_count.render()\n",
        "                # UI.leaf_sample_count.render()\n",
        "\n",
        "                # # Recount on sample_tree change\n",
        "                # UI.sample_tree.change(\n",
        "                #   inputs = UI.project_name,\n",
        "                #   outputs = [ UI.branch_sample_count, UI.leaf_sample_count ],\n",
        "                #   fn = lambda project_name: [\n",
        "                #     len(get_samples(project_name, leafs_only)) for leafs_only in [ False, True ]\n",
        "                #   ]\n",
        "                # )\n",
        "            \n",
        "          UI.picked_sample.render()\n",
        "\n",
        "          UI.sample_tree.change(\n",
        "            inputs = [ UI.project_name, UI.sample_tree ],\n",
        "            outputs = UI.picked_sample,\n",
        "            fn = refresh_siblings,\n",
        "            api_name = 'get-siblings'        \n",
        "          )\n",
        "\n",
        "          preview_inputs = [\n",
        "              UI.project_name, UI.picked_sample, UI.cut_audio_specs, UI.preview_just_the_last_n_sec,\n",
        "              UI.upsample_rendering, UI.combine_upsampling_levels\n",
        "          ]\n",
        "\n",
        "          get_preview_args = lambda force_reload: dict(\n",
        "            inputs = [\n",
        "              *preview_inputs, gr.State(force_reload)\n",
        "            ],\n",
        "            outputs = [\n",
        "              UI.sample_box, UI.current_chunks, #UI.generated_audio,\n",
        "              UI.total_audio_length, UI.upsampled_lengths,\n",
        "              UI.go_to_children_button, UI.go_to_parent_button,\n",
        "              UI.picked_sample_updated\n",
        "            ],\n",
        "            fn = get_sample,\n",
        "          )\n",
        "\n",
        "          default_preview_args = get_preview_args(False)\n",
        "\n",
        "          # Virtual input & handler to create an API method for get_sample_filename\n",
        "          gr.Textbox(visible=False).change(\n",
        "            inputs = preview_inputs,\n",
        "            outputs = gr.Textbox(visible=False),\n",
        "            fn = get_sample_filename,\n",
        "            api_name = 'get-sample-filename'\n",
        "          )\n",
        "\n",
        "          UI.picked_sample.change(\n",
        "            **default_preview_args,\n",
        "            api_name = 'get-sample',\n",
        "            _js =\n",
        "            # Set the search string to ?[sample_id] for easier navigation\n",
        "            '''\n",
        "              async ( ...args ) => {\n",
        "\n",
        "                try {\n",
        "\n",
        "                  let sample_id = args[1]\n",
        "\n",
        "                  sample_id && window.history.pushState( {}, '', `?${args[1]}` )\n",
        "\n",
        "                  // Gray out the wavesurfer\n",
        "                  Ji.grayOutWavesurfer()\n",
        "\n",
        "                  // Now we'll try to reload the audio from cache. To do that, we'll find the first cached blob (Ji.blobCache) whose key starts with the sample_id either followed by space or end of string.\n",
        "                  // (Although different version of the same sample might have been cached, the first one will be the one that was added last, so it's the most recent one)\n",
        "                  let cached_blob = Ji.blobCache.find( ({ key }) => key.match( new RegExp(`^${sample_id}( |$)`) ) )\n",
        "                  if ( cached_blob ) {\n",
        "                    console.log( 'Found cached blob', cached_blob )\n",
        "                    let { key, blob } = cached_blob\n",
        "                    wavesurfer.loadBlob( blob )\n",
        "                    Ji.lastLoadedBlobKey = key\n",
        "                    Ji.preloadedAudio = true\n",
        "                    // Gray out slightly less\n",
        "                    Ji.grayOutWavesurfer( true, 0.75 )\n",
        "                  }\n",
        "\n",
        "                } catch (e) {\n",
        "                  console.error(e)\n",
        "                } finally {\n",
        "\n",
        "                  return args\n",
        "\n",
        "                }\n",
        "\n",
        "\n",
        "              }\n",
        "            '''\n",
        "          )\n",
        "           \n",
        "          # When the picked sample is updated, update all the others too (UI.sibling_chunks) by calling get_sample for each sibling\n",
        "          UI.picked_sample_updated.render().change(\n",
        "            inputs = [ *preview_inputs ],\n",
        "            outputs = UI.sibling_chunks,\n",
        "            fn = get_sibling_samples,\n",
        "            api_name = 'get-sibling-samples',\n",
        "          )\n",
        "\n",
        "          UI.current_chunks.render()\n",
        "          UI.sibling_chunks.render()\n",
        "\n",
        "          UI.upsampled_lengths.render().change(\n",
        "            inputs = UI.upsampled_lengths,\n",
        "            outputs = None,\n",
        "            fn = None,\n",
        "            # Split by comma and turn into floats and add wavesurfer markers for each (first clear all the markers)\n",
        "            _js = 'comma_separated => Ji.addUpsamplingMarkers( comma_separated.split(\",\").map( parseFloat ) )'\n",
        "          )\n",
        "\n",
        "          with UI.sample_box.render():\n",
        "\n",
        "            with UI.upsampling_accordion.render():\n",
        "\n",
        "              with gr.Row():\n",
        "\n",
        "                with gr.Column():\n",
        "\n",
        "                  UI.upsampling_level.render().change(\n",
        "                    **default_preview_args,\n",
        "                  )\n",
        "\n",
        "                  # Only show the upsampling elements if there are upsampled versions of the picked sample\n",
        "                  def show_or_hide_upsampling_elements(project_name, sample_id, upsampling_running):\n",
        "\n",
        "                    levels = get_levels(get_zs(project_name, sample_id))\n",
        "                    # print(f'Levels: {levels}')\n",
        "\n",
        "                    available_level_names = UI.UPSAMPLING_LEVEL_NAMES[:len(levels)]\n",
        "                    print(f'Available level names: {available_level_names}')\n",
        "\n",
        "                    return {\n",
        "                      # UI.upsampling_accordion: gr.update(\n",
        "                      #   visible = len(levels) > 1 or upsampling_running,\n",
        "                      # ),\n",
        "                      # (removing the accordion for now)\n",
        "                      UI.upsampling_status: gr.update(\n",
        "                        visible = upsampling_running,\n",
        "                      ),\n",
        "                      UI.upsampling_level: gr.update(\n",
        "                        choices = available_level_names,\n",
        "                        # Choose the highest available level\n",
        "                        value = available_level_names[-1],\n",
        "                      )\n",
        "                    }\n",
        "                  \n",
        "                  show_or_hide_upsampling_elements_args = dict(\n",
        "                    inputs = [ UI.project_name, UI.picked_sample, UI.upsampling_running ],\n",
        "                    outputs = [ UI.upsampling_status, UI.upsampling_level ],\n",
        "                    fn = show_or_hide_upsampling_elements,\n",
        "                  )\n",
        "\n",
        "                  UI.picked_sample.change( **show_or_hide_upsampling_elements_args )\n",
        "                  UI.upsampling_running.change( **show_or_hide_upsampling_elements_args )\n",
        "\n",
        "                with gr.Column(visible = False) as upsampling_manipulation_column:\n",
        "\n",
        "                  # # Show the column only if an upsampled sample is selected and hide the compose row respectively (we can only compose with the original sample)\n",
        "                  # UI.upsampling_level.change(\n",
        "                  #   inputs = [ UI.upsampling_level, UI.upsampling_running ],\n",
        "                  #   outputs = [ upsampling_manipulation_column, UI.compose_row ],\n",
        "                  #   fn = lambda upsampling_level, upsampling_running: [\n",
        "                  #     gr.update( visible = upsampling_level != 'Raw' ),\n",
        "                  #     gr.update( visible = upsampling_level == 'Raw' and not upsampling_running ),\n",
        "                  #   ]\n",
        "                  # )\n",
        "\n",
        "                  with gr.Row():\n",
        "\n",
        "                    UI.upsample_rendering.render().change(\n",
        "                      **default_preview_args,\n",
        "                    )\n",
        "\n",
        "                    UI.combine_upsampling_levels.render().change(\n",
        "                      **default_preview_args,\n",
        "                    )\n",
        "\n",
        "              # Show the continue upsampling markdown only if the current level's length in tokens is less than the total audio length\n",
        "              # Also update the upsampling button to say \"Continue upsampling\" instead of \"Upsample\"\n",
        "              def show_or_hide_continue_upsampling(project_name, sample_id, total_audio_length, upsampling_running):\n",
        "\n",
        "                if not upsampling_running:\n",
        "                  zs = get_zs(project_name, sample_id)\n",
        "                  levels = get_levels(zs)\n",
        "                  # print(f'Levels: {levels}, z: {zs}')\n",
        "                  # We'll show if there's no level 0 in levels or if the length of level 0 (in seconds) is less than the length of level 2 (in seconds)\n",
        "                  must_show = 0 not in levels or tokens_to_seconds(len(zs[0]), 0) < tokens_to_seconds(len(zs[2]), 2)\n",
        "                  # print(f'Must show: {must_show}')\n",
        "                  \n",
        "                else:\n",
        "                  must_show = True\n",
        "\n",
        "                return gr.update( visible = must_show )\n",
        "              \n",
        "              UI.picked_sample.change(\n",
        "                inputs = [ UI.project_name, UI.picked_sample, UI.total_audio_length, UI.upsampling_running ],\n",
        "                outputs = UI.continue_upsampling_button,\n",
        "                fn = show_or_hide_continue_upsampling,\n",
        "              )\n",
        "\n",
        "              upsample_button_click_args = dict(\n",
        "                inputs = UI.upsampling_running,\n",
        "                outputs = [ UI.upsampling_running, UI.upsampling_triggered_by_button ],\n",
        "                fn = lambda was_running: \n",
        "                # If was running (i.e. we're stopping), kill the runtime (after a warning) and show an alert saying to restart the runtime in Colab\n",
        "                  [\n",
        "                    print('Killing runtime...'),\n",
        "                    subprocess.run(['kill', '-9', str(os.getpid())]),\n",
        "                  ] if was_running else {\n",
        "                    UI.upsampling_running: 1,\n",
        "                    UI.upsampling_triggered_by_button: True,\n",
        "                  },\n",
        "                _js = \"\"\"\n",
        "                  // Confirm before starting/stopping the upsample process\n",
        "                  running => {\n",
        "                    confirmText = \n",
        "                      running ?\n",
        "                        'Are you sure you want to stop the upsample process? âš ï¸ THIS WILL KILL THE RUNTIME AND YOU WILL HAVE TO RESTART IT IN COLAB âš ï¸ (But your current upsampling progress will be saved)' :\n",
        "                        'Are you sure you want to start the upsample process? THIS WILL TAKE HOURS, AND YOU WONâ€™T BE ABLE TO CONTINUE COMPOSING!'\n",
        "                    if ( !confirm(confirmText) ) {\n",
        "                      throw new Error(`${running ? 'Stopping' : 'Starting'} upsample process canceled by user`)\n",
        "                    } else {\n",
        "                      // If running, show a message saying to restart the runtime in Colab\n",
        "                      if ( running ) {\n",
        "                        alert('Upsample process stopped. Please re-run the cell in Colab to restart the UI')\n",
        "                      }\n",
        "                      return [ running ]\n",
        "                    }\n",
        "                  }\n",
        "                \"\"\"\n",
        "              )\n",
        "\n",
        "              UI.continue_upsampling_button.render().click( **upsample_button_click_args )\n",
        "\n",
        "              UI.upsampling_audio_refresher.render()\n",
        "\n",
        "              def reset_audio_refresher():\n",
        "                Upsampling.should_refresh_audio = False\n",
        "\n",
        "              [ \n",
        "                UI.upsampling_audio_refresher.change( **action ) for action in [ \n",
        "                  default_preview_args, \n",
        "                  show_or_hide_upsampling_elements_args,\n",
        "                  dict(\n",
        "                    inputs = None,\n",
        "                    outputs = None,\n",
        "                    # Reset Upsampling.should_refresh_audio to False\n",
        "                    fn = reset_audio_refresher\n",
        "                  )\n",
        "                ] \n",
        "              ]\n",
        "\n",
        "            UI.upsampling_status.render()\n",
        "            \n",
        "            # Refresh button\n",
        "            internal_refresh_button = gr.Button('ðŸ”ƒ', elem_id = 'internal-refresh-button', visible=False)\n",
        "            \n",
        "            internal_refresh_button.click(\n",
        "              **get_preview_args(force_reload = True),\n",
        "            )\n",
        "\n",
        "            internal_refresh_button.click(\n",
        "              **show_or_hide_upsampling_elements_args,\n",
        "            )\n",
        "                \n",
        "            for element in [ \n",
        "              UI.audio_waveform,\n",
        "              UI.audio_timeline\n",
        "            ]:\n",
        "              element.render()\n",
        "\n",
        "\n",
        "            # Play/pause button, js-based\n",
        "            gr.HTML(\"\"\"\n",
        "              <!-- Button to play/pause the audio -->\n",
        "              <button class=\"gr-button gr-button-lg gr-button-secondary\"\n",
        "                onclick = \"\n",
        "                  wavesurfer.playPause()\n",
        "                  this.innerText = wavesurfer.isPlaying() ? 'â¸ï¸' : 'â–¶ï¸'\n",
        "                \"\n",
        "              >â–¶ï¸</button>\n",
        "\n",
        "              <!-- Textbox showing current time -->\n",
        "              <input type=\"number\" class=\"gr-box gr-input gr-text-input\" id=\"audio-time\" value=\"0\">\n",
        "\n",
        "              <!-- Download button -- it will be set to the right href later on -->\n",
        "              <!--\n",
        "              <a class=\"gr-button gr-button-lg gr-button-secondary\" id=\"download-button\">\n",
        "                ðŸ”—\n",
        "              </a>\n",
        "              -->\n",
        "              <!-- (Removed for now, as it only links to the first chunk, will fix later) -->\n",
        "\n",
        "              <!-- Refresh button -- it virtually clicks the \"internal-refresh-button\" button (which is hidden) -->\n",
        "              <button class=\"gr-button gr-button-lg gr-button-secondary\" onclick=\"window.shadowRoot.getElementById('internal-refresh-button').click()\" id=\"refresh-button\">\n",
        "                â†»\n",
        "              </button>\n",
        "            \"\"\")\n",
        "\n",
        "            with UI.compose_row.render():\n",
        "\n",
        "              gr.Button(\n",
        "                value = 'Go on',\n",
        "                variant = 'primary',\n",
        "              ).click(\n",
        "                inputs =  [ UI.project_name, UI.picked_sample, UI.show_leafs_only, *UI.generation_params ],\n",
        "                outputs = [ UI.sample_tree, UI.generation_progress ],\n",
        "                fn = generate,\n",
        "              )\n",
        "\n",
        "              gr.Button(\n",
        "                value = 'More variations',          \n",
        "              ).click(\n",
        "                inputs = [ UI.project_name, UI.picked_sample, UI.show_leafs_only, *UI.generation_params ],\n",
        "                outputs = [ UI.sample_tree, UI.generation_progress ],\n",
        "                fn = lambda project_name, sample_id, *args: generate(project_name, get_parent(project_name, sample_id), *args),\n",
        "              )\n",
        "\n",
        "              UI.go_to_parent_button.render()\n",
        "              UI.go_to_parent_button.click(\n",
        "                inputs = [ UI.project_name, UI.picked_sample ],\n",
        "                outputs = UI.sample_tree,\n",
        "                fn = get_parent\n",
        "              )\n",
        "\n",
        "              UI.go_to_children_button.render()\n",
        "              UI.go_to_children_button.click(\n",
        "                inputs = [ UI.project_name, UI.picked_sample ], \n",
        "                outputs = UI.sample_tree,\n",
        "                fn = lambda project_name, sample_id: get_children(project_name, sample_id)[0]\n",
        "              )\n",
        "\n",
        "              gr.Button('ðŸ—‘ï¸').click(\n",
        "                inputs = [ UI.project_name, UI.picked_sample, gr.Checkbox(visible=False) ],\n",
        "                outputs = [ UI.picked_sample, UI.sample_box ],\n",
        "                fn = delete_sample,\n",
        "                _js = \"\"\"\n",
        "                  ( project_name, child_sample_id ) => {\n",
        "                    if ( confirm('Are you sure? There is no undo!') ) {\n",
        "                      return [ project_name, child_sample_id, true ]\n",
        "                    } else {\n",
        "                      throw new Error('Cancelled; not deleting')\n",
        "                    }\n",
        "                  }\n",
        "                \"\"\",\n",
        "                api_name = 'delete-sample'\n",
        "              )\n",
        "\n",
        "            with gr.Accordion( 'Advanced', open = False ):\n",
        "\n",
        "              with gr.Tab('Manipulate audio'):\n",
        "\n",
        "                UI.total_audio_length.render()\n",
        "\n",
        "                # Change the max n samples depending on the audio length\n",
        "                def set_max_n_samples( total_audio_length, n_samples ):\n",
        "\n",
        "                  max_n_samples_by_gpu_and_duration = {\n",
        "                    'Tesla T4': {\n",
        "                      0: 4,\n",
        "                      8.5: 3,\n",
        "                      13: 2\n",
        "                    }\n",
        "                    # The key indicates the audio length threshold in seconds trespassing which makes max_n_samples equal to the value\n",
        "                  }\n",
        "\n",
        "                  # Get GPU via nvidia-smi\n",
        "                  gpu = subprocess.check_output( 'nvidia-smi --query-gpu=gpu_name --format=csv,noheader', shell=True ).decode('utf-8').strip()\n",
        "\n",
        "                  # The default value is 4\n",
        "                  max_n_samples = 4\n",
        "                  if gpu in max_n_samples_by_gpu_and_duration and total_audio_length:\n",
        "                    # Get the max n samples for the GPU from the respective dict\n",
        "                    max_n_samples_for_gpu = max_n_samples_by_gpu_and_duration[gpu]\n",
        "                    max_n_samples_above_threshold = [ max_n_samples_for_gpu[threshold] for threshold in max_n_samples_for_gpu if total_audio_length > threshold ]\n",
        "                    if len(max_n_samples_above_threshold) > 0:\n",
        "                      max_n_samples = min( max_n_samples_for_gpu[ threshold ] for threshold in max_n_samples_for_gpu if total_audio_length > threshold )\n",
        "\n",
        "                  return max_n_samples\n",
        "\n",
        "                # Do this on audio length change and app load\n",
        "                for handler in [ UI.total_audio_length.change, app.load ]:\n",
        "                  handler(\n",
        "                    inputs = [ UI.total_audio_length, UI.n_samples ],\n",
        "                    outputs = UI.max_n_samples,\n",
        "                    fn = set_max_n_samples,\n",
        "                  )\n",
        "                \n",
        "                # If max_n_samples changes, update the n_samples input respectively\n",
        "                UI.max_n_samples.render().change(\n",
        "                  inputs = UI.max_n_samples,\n",
        "                  outputs = UI.n_samples,\n",
        "                  fn = lambda max_n_samples: gr.update(\n",
        "                    maximum = max_n_samples,\n",
        "                    # value = min( n_samples, max_n_samples ),\n",
        "                  )\n",
        "                )\n",
        "\n",
        "                UI.cut_audio_specs.render().submit(**default_preview_args)\n",
        "\n",
        "                with gr.Row():\n",
        "\n",
        "                  UI.cut_audio_preview_button.render().click(**default_preview_args)\n",
        "\n",
        "                  # Make the cut out buttons visible or not depending on whether the cut out value is 0\n",
        "                  UI.cut_audio_specs.change(\n",
        "                    inputs = UI.cut_audio_specs,\n",
        "                    outputs = [ UI.cut_audio_preview_button, UI.cut_audio_apply_button ],\n",
        "                    fn = lambda cut_audio_specs: [\n",
        "                      gr.update( visible = cut_audio_specs != '' ) for _ in range(3)\n",
        "                    ]\n",
        "                  )\n",
        "\n",
        "                  UI.cut_audio_apply_button.render().click(\n",
        "                    inputs = [ UI.project_name, UI.picked_sample, UI.cut_audio_specs ],\n",
        "                    outputs = UI.cut_audio_specs,\n",
        "                    fn = cut_audio,\n",
        "                    api_name = 'cut-audio',\n",
        "                  )\n",
        "\n",
        "                with gr.Accordion('How does it work?', open = False):\n",
        "                  # possible specs:\n",
        "                  # start-end -- cuts out the specified range (in seconds), either can be omitted to cut from the start or to the end, the dash can be omitted to cut from the specified time to the end\n",
        "                  # start-end+sample_id@start-end -- takes the specified range from the specified sample and adds it instead of the cut-out range\n",
        "                  # start-end+start-end -- same, but takes the specified range from the current sample\n",
        "                  # +sample_id@start-end -- adds the specified range from the specified sample to the end of the current sample\n",
        "                  # +start-end -- keeps just the specified range from the current sample (i.e. the opposite of start-end)\n",
        "                  # Any whitespaces are ignored\n",
        "                  gr.Markdown('''\n",
        "                    - `start-end` (e.g. 0.5-2.5) â€” *removes* the specified range (in seconds),\n",
        "                      - `start-` or just `start` â€” *removes* from the specified time to the end\n",
        "                      - `-end` -- **removes** from the start to the specified time\n",
        "                    - `start-end+start-end` â€” *removes* the range before `+` and *inserts* the range after `+` instead. Note that, unlike the remove range, the insert range must be fully specified.\n",
        "                    - `start-end+sample_id@start-end` â€” same as above, but the insert range is taken from the specified sample, even if it is in another project (mix and match!)\n",
        "                    - `+sample_id@start-end` â€” same as above, but the range from the other sample is added *to the end* of the current sample\n",
        "                    - `+start-end` â€” *keeps* just the specified range and removes everything else.\n",
        "\n",
        "                    You can combine several of the above by using a comma (`,`). **KEEP IN MIND** that in this case the ranges are applied sequentially, so the order matters. For example, `0-1,2-3` will first remove 0-1s, and will then remove 2-3s FROM THE ALREADY MODIFIED SAMPLE, so it will actually remove ranges 0-1s and *3-4s* from the original sample. This is intentional, as it allows for a step-by-step approach to editing the audio, where you add new specifiers as you listen to the result of the previous ones.\n",
        "                  ''')\n",
        "\n",
        "                UI.preview_just_the_last_n_sec.render().blur(**default_preview_args)\n",
        "\n",
        "              with gr.Tab('Rename sample'):\n",
        "\n",
        "                new_sample_id = gr.Textbox(\n",
        "                  label = 'New sample id',\n",
        "                  placeholder = 'Alphanumeric and dashes only'\n",
        "                )\n",
        "\n",
        "                gr.Button('Rename').click(\n",
        "                  inputs = [ UI.project_name, UI.picked_sample, new_sample_id, UI.show_leafs_only ],\n",
        "                  outputs = UI.sample_tree,\n",
        "                  fn = rename_sample,\n",
        "                  api_name = 'rename-sample'\n",
        "                )\n",
        "        \n",
        "        UI.generation_progress.render()\n",
        "\n",
        "\n",
        "      with gr.Tab('Prime'):\n",
        "\n",
        "        primed_audio_source = gr.Radio(\n",
        "          label = 'Audio source',\n",
        "          choices = [ 'microphone', 'upload' ],\n",
        "          value = 'microphone'\n",
        "        )\n",
        "\n",
        "        UI.primed_audio.render()\n",
        "        \n",
        "        primed_audio_source.change(\n",
        "          inputs = primed_audio_source,\n",
        "          outputs = UI.primed_audio,\n",
        "          fn = lambda source: gr.update( source = source ),\n",
        "        )\n",
        "\n",
        "        sec_to_trim_primed_audio = gr.Number(\n",
        "          label = 'Trim starting audio to ... seconds from the beginning',\n",
        "        )\n",
        "\n",
        "        def trim_primed_audio(audio, sec):\n",
        "          print(f'Trimming {audio} to {sec} seconds')\n",
        "          # # Plot the audio to console for debugging\n",
        "          # plt.plot(audio)\n",
        "          # plt.show()              \n",
        "          # Audio is of the form (sr, audio)\n",
        "          trimmed_audio = audio[1][:int(sec * audio[0])]\n",
        "          print(f'Trimmed audio shape is {trimmed_audio.shape}')\n",
        "          return ( audio[0], trimmed_audio )\n",
        "\n",
        "        sec_to_trim_primed_audio.submit(\n",
        "          inputs = [ UI.primed_audio, sec_to_trim_primed_audio ],\n",
        "          outputs = UI.primed_audio,\n",
        "          fn = trim_primed_audio\n",
        "        )\n",
        "\n",
        "        prime_button = gr.Button(\n",
        "          'Convert to sample',\n",
        "          variant = 'primary'\n",
        "        )\n",
        "                \n",
        "        prime_button.click(\n",
        "          inputs = [ UI.project_name, UI.primed_audio, sec_to_trim_primed_audio, UI.show_leafs_only ],\n",
        "          outputs = [ UI.sample_tree, prime_button, UI.prime_timestamp, UI.first_generation_row ], # UI.prime_timestamp is updated to the current time to force tab change\n",
        "          fn = convert_audio_to_sample,\n",
        "          api_name = 'convert-wav-to-sample'\n",
        "        )\n",
        "\n",
        "        UI.prime_timestamp.render().change(\n",
        "          inputs = UI.prime_timestamp, outputs = None, fn = None,\n",
        "          _js = \n",
        "            # Find a button inside a div inside another div with class 'tabs', the button having 'Workspace' as text, and click it -- all this in the shadow DOM.\n",
        "            # Gosh, this is ugly.\n",
        "            \"\"\"\n",
        "              timestamp => {\n",
        "                console.log(`Timestamp changed to ${timestamp}; clicking the 'Workspace' tab`)\n",
        "                Ji.clickTabWithText('Workspace')\n",
        "                return timestamp\n",
        "              }\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "      with gr.Tab('Upsample'):\n",
        "\n",
        "        # Warning that this process is slow and can take up to 10 minutes for 1 second of audio\n",
        "        with gr.Accordion('What is this?', open = False):\n",
        "\n",
        "          gr.Markdown('''\n",
        "            Upsampling is a process that creates higher-quality audio from your composition. It is done in two steps:\n",
        "\n",
        "            - â€œMidsampling,â€ which considerably improves the quality of the audio, takes around 2 minutes per one second of audio.\n",
        "\n",
        "            - â€œUpsampling,â€ which improves the quality some more, goes after midsampling and takes around 8 minutes per one second of audio.\n",
        "\n",
        "            Thus, say, for a one-minute song, you will need to wait around 2 hours to have the midsampled version, and around 8 hours _more_ to have the upsampled version.\n",
        "\n",
        "            You will be able to listen to the audio as it is being generated: Each â€œwindowâ€ of upsampling takes ~6 minutes and will give you respectively ~2.7 and ~0.7 additional seconds of mid- or upsampled audio to listen to.\n",
        "\n",
        "            âš ï¸ WARNING: As the upsampling process uses a different model, which cannot be loaded together with the composition model due to memory constraints, **you will not be able to upsample and compose at the same time**. To go back to composing you will have to restart the Colab runtime or start a second Colab runtime and use them in parallel.\n",
        "          ''')\n",
        "\n",
        "        UI.sample_to_upsample.render()\n",
        "\n",
        "        # Change the sample to upsample when a sample is picked\n",
        "        UI.picked_sample.change(\n",
        "          inputs = UI.picked_sample,\n",
        "          outputs = UI.sample_to_upsample,\n",
        "          fn = lambda x: x,\n",
        "        )\n",
        "\n",
        "        with gr.Accordion('Genres for upsampling (optional)', open = False):\n",
        "\n",
        "          with gr.Accordion('What is this?', open = False):\n",
        "\n",
        "            gr.Markdown('''\n",
        "              The tool will generate three upsamplings of the selected sample, which will then be panned to the left, center, and right, respectively. Choosing different genres for each of the three upsamplings will result in a more diverse sound between them, thus enhancing the (pseudo-)stereo effect. \n",
        "\n",
        "              A good starting point is to have a genre that emphasizes vocals (e.g. `Pop`) for the center channel, and two similar but different genres for the left and right channels (e.g. `Rock` and `Metal`).\n",
        "\n",
        "              If you donâ€™t want to use this feature, simply select the same genre for all three upsamplings.\n",
        "            ''')\n",
        "\n",
        "          with gr.Row():\n",
        "\n",
        "            for input in [ UI.genre_for_upsampling_left_channel, UI.genre_for_upsampling_center_channel, UI.genre_for_upsampling_right_channel ]:\n",
        "\n",
        "              input.render()\n",
        "          \n",
        "          UI.kill_runtime_once_done.render()\n",
        "        \n",
        "        # If upsampling is running, enable the upsampling_refresher -- a \"virtual\" input that, when changed, will update the upsampling_status_markdown\n",
        "        # It will do so after waiting for 10 seconds (using js). After finishing, it will update itself again, causing the process to repeat.\n",
        "        UI.upsampling_refresher.render().change(\n",
        "          inputs = [ UI.upsampling_refresher, UI.upsampling_audio_refresher ],\n",
        "          outputs = [ UI.upsampling_refresher, UI.upsampling_status, UI.upsampling_audio_refresher ],\n",
        "          fn = lambda refresher, audio_refresher: {\n",
        "            UI.upsampling_status: Upsampling.status_markdown,\n",
        "            UI.upsampling_refresher: refresher + 1,\n",
        "            UI.upsampling_audio_refresher: audio_refresher + 1 if Upsampling.should_refresh_audio else audio_refresher\n",
        "          },\n",
        "          _js = \"\"\"\n",
        "            async ( ...args ) => {\n",
        "              await new Promise( resolve => setTimeout( resolve, 10000 ) )\n",
        "              console.log( 'Checking upsampling status...' )\n",
        "              return args\n",
        "            }\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "        UI.upsample_button.render().click( **upsample_button_click_args )\n",
        "\n",
        "        # During app load, set upsampling_running and upsampling_stopping according to Upsampling.running\n",
        "        app.load(\n",
        "          inputs = None,\n",
        "          outputs = UI.upsampling_running,\n",
        "          fn = lambda: Upsampling.running,\n",
        "        )\n",
        "        \n",
        "        UI.upsampling_triggered_by_button.render()\n",
        "\n",
        "        # When upsampling_running changes via the button, run the upsampling process\n",
        "        UI.upsampling_running.render().change(\n",
        "          inputs = [\n",
        "            UI.upsampling_triggered_by_button,\n",
        "            UI.project_name, UI.sample_to_upsample, UI.artist, UI.lyrics,\n",
        "            UI.genre_for_upsampling_left_channel, UI.genre_for_upsampling_center_channel, UI.genre_for_upsampling_right_channel,\n",
        "            UI.kill_runtime_once_done            \n",
        "          ],\n",
        "          outputs = None,\n",
        "          fn = lambda triggered_by_button, *args: start_upsampling( *args ) if triggered_by_button else None,\n",
        "          api_name = 'toggle-upsampling',\n",
        "          # Also go to the \"Workspace\" tab (because that's where we'll display the upsampling status) via the Ji.clickTabWithText helper method in js\n",
        "          _js = \"\"\"\n",
        "            async ( ...args ) => {\n",
        "              console.log( 'Upsampling toggled, args:', args )\n",
        "              if ( args[0] ) {\n",
        "                Ji.clickTabWithText( 'Workspace' )\n",
        "                return args\n",
        "              } else {\n",
        "                throw new Error('Upsampling not triggered by button')\n",
        "              }\n",
        "            }\n",
        "          \"\"\"\n",
        "        )\n",
        "\n",
        "        # When it changes regardless of the session, e.g. also at page refresh, update the various relevant UI elements, start the refresher, etc.\n",
        "        UI.upsampling_running.change(\n",
        "          inputs = None,\n",
        "          outputs = [ UI.upsampling_status, UI.upsample_button, UI.continue_upsampling_button, UI.upsampling_refresher ],\n",
        "          fn = lambda: {\n",
        "            UI.upsampling_status: 'Upsampling in progress...',\n",
        "            UI.upsample_button: gr.update(\n",
        "              value = 'Stop upsampling',\n",
        "              variant = 'secondary',\n",
        "            ),\n",
        "            UI.continue_upsampling_button: gr.update(\n",
        "              value = 'Stop upsampling',\n",
        "            ),\n",
        "            # Random refresher value (int) to trigger the refresher\n",
        "            UI.upsampling_refresher: random.randint( 0, 1000000 ),\n",
        "            # # Hide the compose row\n",
        "            # UI.compose_row: HIDE,\n",
        "          }\n",
        "        )\n",
        "\n",
        "      with gr.Tab('Panic'):\n",
        "\n",
        "        with gr.Accordion('What is this?', open = False):\n",
        "\n",
        "          gr.Markdown('''\n",
        "            Sometimes the app will crash due to insufficient GPU memory. If this happens, you can try using the button below to empty the cache. Usually around 12 GB of GPU RAM is needed to safely run the app.\n",
        "\n",
        "            If that doesnâ€™t work, youâ€™ll have to restart the runtime (`Runtime` > `Restart and run all` in Colab). Thatâ€™ll take a couple of minutes, but the memory will be new as a daisy.\n",
        "          ''')\n",
        "\n",
        "        memory_usage = gr.Textbox(\n",
        "          label = 'GPU memory usage',\n",
        "          value = 'Click Refresh to update',\n",
        "        )\n",
        "\n",
        "        def get_gpu_memory_usage():\n",
        "          return subprocess.check_output(\n",
        "            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader'],\n",
        "            encoding='utf-8'\n",
        "          ).strip()\n",
        "\n",
        "        with gr.Row():\n",
        "        \n",
        "          gr.Button('Refresh').click(\n",
        "            inputs = None,\n",
        "            outputs = memory_usage,\n",
        "            fn = get_gpu_memory_usage,\n",
        "            api_name = 'get-gpu-memory-usage',\n",
        "          )\n",
        "\n",
        "          gr.Button('Empty cache', variant='primary').click(\n",
        "            inputs = None,\n",
        "            outputs = memory_usage,\n",
        "            fn = lambda: [\n",
        "              empty_cache(),\n",
        "              get_gpu_memory_usage(),\n",
        "            ][-1],\n",
        "            api_name = 'empty-cache',\n",
        "          )\n",
        "\n",
        "        with gr.Accordion('Run any code', open = False, visible = DEV_MODE):\n",
        "\n",
        "          gr.Markdown('''\n",
        "            The following input box allows you to execute arbitrary Python code. âš ï¸ DONâ€™T USE THIS FEATURE IF YOU DONâ€™T KNOW WHAT YOUâ€™RE DOING! âš ï¸\n",
        "          ''')\n",
        "\n",
        "          eval_server_code = gr.Textbox(\n",
        "            label = 'Python code',\n",
        "            placeholder = 'Shift+Enter for a new line, Enter to run',\n",
        "            value = '',\n",
        "            max_lines = 10,\n",
        "          )\n",
        "\n",
        "          eval_button = gr.Button('Execute')\n",
        "\n",
        "          eval_output = gr.Textbox(\n",
        "            label = 'Output',\n",
        "            value = '',\n",
        "            max_lines = 10,\n",
        "          )\n",
        "\n",
        "          eval_args = dict(\n",
        "            inputs = eval_server_code,\n",
        "            outputs = eval_output,\n",
        "            fn = lambda code: {\n",
        "              eval_output: eval( code )\n",
        "            }\n",
        "          )\n",
        "\n",
        "          eval_button.click(**eval_args)\n",
        "          eval_server_code.submit(\n",
        "            **eval_args,\n",
        "            api_name = 'eval-code',\n",
        "          )\n",
        "\n",
        "  # TODO: Don't forget to remove this line before publishing the app\n",
        "  frontend_on_load_url = f'https://cdn.jsdelivr.net/gh/vzakharov/jukebox-webui@{GITHUB_SHA}/frontend-on-load.js'\n",
        "  with urllib.request.urlopen(frontend_on_load_url) as response:\n",
        "    frontend_on_load_js = response.read().decode('utf-8')\n",
        "\n",
        "    try:\n",
        "      old_frontend_on_load_md5 = frontend_on_load_md5\n",
        "    except NameError:\n",
        "      old_frontend_on_load_md5 = None\n",
        "\n",
        "    frontend_on_load_md5 = hashlib.md5(frontend_on_load_js.encode('utf-8')).hexdigest()\n",
        "    print(f'Loaded frontend-on-load.js from {response.geturl()}, md5: {frontend_on_load_md5}')\n",
        "\n",
        "    if frontend_on_load_md5 != old_frontend_on_load_md5:\n",
        "      print('(New version)')\n",
        "    else:\n",
        "      print('(Same version as during the previous run)')\n",
        "\n",
        "    # print(frontend_on_load_js)\n",
        "\n",
        "  app.load(\n",
        "    on_load,\n",
        "    inputs = [ gr.Textbox(visible=False), gr.Textbox(visible=False), gr.Textbox(visible=False) ],\n",
        "    outputs = [ \n",
        "      UI.project_name, UI.routed_sample_id, UI.artist, UI.genre, UI.getting_started_column, UI.separate_tab_warning, UI.separate_tab_link, UI.main_window,\n",
        "      UI.genre_for_upsampling_left_channel, UI.genre_for_upsampling_center_channel, UI.genre_for_upsampling_right_channel\n",
        "    ],\n",
        "    api_name = 'initialize',\n",
        "    _js = frontend_on_load_js,\n",
        "    # _js = \"\"\"\n",
        "    # // (insert manually for debugging)\n",
        "    # \"\"\",\n",
        "  )\n",
        "\n",
        "  # Also load browser's time zone offset on app load\n",
        "  def set_browser_timezone(offset):\n",
        "    global browser_timezone\n",
        "\n",
        "    print('Browser time zone offset:', offset)\n",
        "    browser_timezone = timezone(timedelta(minutes = -offset))\n",
        "    print('Browser time zone:', browser_timezone)\n",
        "\n",
        "  app.load(\n",
        "    inputs = gr.Number( visible = False ),\n",
        "    outputs = None,\n",
        "    _js = '() => [ new Date().getTimezoneOffset() ]',\n",
        "    fn = set_browser_timezone\n",
        "  )\n",
        "\n",
        "\n",
        "  app.launch( share = share_gradio, debug = debug_gradio )"
      ],
      "metadata": {
        "id": "mJYTvYjBQQmG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qH5vLL1klF7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}